{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome Prediction with RGCN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data from \"processed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter, Linear\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.logging import log\n",
    "from torch_geometric.nn import RGCNConv\n",
    "from torch_geometric.utils import to_undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 221870], edge_type=[221870], train_idx=[800], train_y=[800], valid_idx=[100], valid_y=[100], test_idx=[100], test_y=[100], num_nodes=33563, x=[33563, 100], num_x=[33563, 1], num_relations=10, num_classes=3)\n"
     ]
    }
   ],
   "source": [
    "num_patients = 1000\n",
    "inverse_triples=True\n",
    "embed_dim = 100\n",
    "\n",
    "entity = pd.read_csv(f'processed_data/sphn_entities_{num_patients}_noOutcome.tsv', sep='\\t', header=None)\n",
    "entity = entity.set_index(entity[0])\n",
    "entity = entity.to_dict()[1]\n",
    "\n",
    "indices = []\n",
    "for i in range(num_patients):\n",
    "    idx = f'<http://nvasc.org/synth_patient_{i}>'\n",
    "    indices.append(entity[idx])\n",
    "\n",
    "events = pd.read_csv(f'processed_data/sphn_events_{num_patients}_noOutcome.tsv', sep='\\t', header=None)\n",
    "y = joblib.load(f'../Data Generation/outcomes_{num_patients}_0.joblib')\n",
    "num_x = torch.Tensor(np.load(f'processed_data/sphn_numeric_{num_patients}.npy'))\n",
    "\n",
    "non_test_X, test_X, non_test_y, test_y_ = train_test_split(indices, y, stratify=y, test_size=0.1, random_state=0)\n",
    "train_X, valid_X, train_y_, valid_y_ = train_test_split(non_test_X, non_test_y, stratify=non_test_y, test_size=1./9)\n",
    "class_weight = compute_class_weight(class_weight=\"balanced\", classes=np.unique(train_y_), y=train_y_)\n",
    "\n",
    "edge_index = torch.vstack((torch.Tensor(events[0]).long(),torch.Tensor(events[2]).long()))\n",
    "edge_type = torch.Tensor(events[1]).long()\n",
    "train_idx = torch.Tensor(train_X).long()\n",
    "train_y = torch.Tensor(train_y_).long()\n",
    "valid_idx = torch.Tensor(valid_X).long()\n",
    "valid_y = torch.Tensor(valid_y_).long()\n",
    "test_idx = torch.Tensor(test_X).long()\n",
    "test_y = torch.Tensor(test_y_).long()\n",
    "num_nodes = len(entity)\n",
    "\n",
    "if inverse_triples == True:\n",
    "    edge_index = to_undirected(edge_index)\n",
    "    edge_type = torch.cat((edge_type, edge_type))\n",
    "\n",
    "data = Data(\n",
    "    edge_index=edge_index,\n",
    "    edge_type=edge_type,\n",
    "    train_idx=train_idx,\n",
    "    train_y=train_y,\n",
    "    valid_idx=valid_idx,\n",
    "    valid_y=valid_y,\n",
    "    test_idx=test_idx,\n",
    "    test_y=test_y,\n",
    "    num_nodes=num_nodes,\n",
    ")\n",
    "embedding = Parameter(torch.empty(num_nodes, embed_dim))\n",
    "torch.nn.init.xavier_uniform_(embedding, gain=math.sqrt(2.0))\n",
    "data.x = embedding\n",
    "data.num_x = num_x.view(-1,1)\n",
    "data.num_relations = data.num_edge_types\n",
    "data.num_classes = 3\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 1.2202, Train: 0.3762, Val: 0.4000, Test: 0.3400\n",
      "Epoch: 002, Loss: 1.2049, Train: 0.2937, Val: 0.3200, Test: 0.3400\n",
      "Epoch: 003, Loss: 1.2019, Train: 0.2237, Val: 0.2100, Test: 0.3400\n",
      "Epoch: 004, Loss: 1.1987, Train: 0.1637, Val: 0.1600, Test: 0.3400\n",
      "Epoch: 005, Loss: 1.1903, Train: 0.1325, Val: 0.1400, Test: 0.3400\n",
      "Epoch: 006, Loss: 1.1844, Train: 0.1225, Val: 0.1300, Test: 0.3400\n",
      "Epoch: 007, Loss: 1.1790, Train: 0.1163, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 008, Loss: 1.1782, Train: 0.1150, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 009, Loss: 1.1804, Train: 0.1150, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 010, Loss: 1.1777, Train: 0.1150, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 011, Loss: 1.1735, Train: 0.1150, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 012, Loss: 1.1725, Train: 0.1150, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 013, Loss: 1.1751, Train: 0.1150, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 014, Loss: 1.1760, Train: 0.1150, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 015, Loss: 1.1623, Train: 0.1150, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 016, Loss: 1.1723, Train: 0.1150, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 017, Loss: 1.1723, Train: 0.1150, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 018, Loss: 1.1622, Train: 0.1150, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 019, Loss: 1.1672, Train: 0.1150, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 020, Loss: 1.1656, Train: 0.1150, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 021, Loss: 1.1579, Train: 0.1150, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 022, Loss: 1.1585, Train: 0.1150, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 023, Loss: 1.1622, Train: 0.1150, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 024, Loss: 1.1553, Train: 0.1163, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 025, Loss: 1.1628, Train: 0.1175, Val: 0.1200, Test: 0.3400\n",
      "Epoch: 026, Loss: 1.1529, Train: 0.1187, Val: 0.1300, Test: 0.3400\n",
      "Epoch: 027, Loss: 1.1553, Train: 0.1200, Val: 0.1300, Test: 0.3400\n",
      "Epoch: 028, Loss: 1.1538, Train: 0.1200, Val: 0.1300, Test: 0.3400\n",
      "Epoch: 029, Loss: 1.1497, Train: 0.1225, Val: 0.1300, Test: 0.3400\n",
      "Epoch: 030, Loss: 1.1463, Train: 0.1262, Val: 0.1300, Test: 0.3400\n",
      "Epoch: 031, Loss: 1.1481, Train: 0.1262, Val: 0.1300, Test: 0.3400\n",
      "Epoch: 032, Loss: 1.1412, Train: 0.1262, Val: 0.1300, Test: 0.3400\n",
      "Epoch: 033, Loss: 1.1406, Train: 0.1300, Val: 0.1300, Test: 0.3400\n",
      "Epoch: 034, Loss: 1.1377, Train: 0.1337, Val: 0.1300, Test: 0.3400\n",
      "Epoch: 035, Loss: 1.1438, Train: 0.1350, Val: 0.1300, Test: 0.3400\n",
      "Epoch: 036, Loss: 1.1388, Train: 0.1388, Val: 0.1300, Test: 0.3400\n",
      "Epoch: 037, Loss: 1.1385, Train: 0.1400, Val: 0.1300, Test: 0.3400\n",
      "Epoch: 038, Loss: 1.1280, Train: 0.1425, Val: 0.1300, Test: 0.3400\n",
      "Epoch: 039, Loss: 1.1327, Train: 0.1437, Val: 0.1400, Test: 0.3400\n",
      "Epoch: 040, Loss: 1.1311, Train: 0.1462, Val: 0.1400, Test: 0.3400\n",
      "Epoch: 041, Loss: 1.1324, Train: 0.1538, Val: 0.1400, Test: 0.3400\n",
      "Epoch: 042, Loss: 1.1292, Train: 0.1587, Val: 0.1400, Test: 0.3400\n",
      "Epoch: 043, Loss: 1.1207, Train: 0.1650, Val: 0.1400, Test: 0.3400\n",
      "Epoch: 044, Loss: 1.1211, Train: 0.1700, Val: 0.1400, Test: 0.3400\n",
      "Epoch: 045, Loss: 1.1158, Train: 0.1787, Val: 0.1400, Test: 0.3400\n",
      "Epoch: 046, Loss: 1.1164, Train: 0.1875, Val: 0.1400, Test: 0.3400\n",
      "Epoch: 047, Loss: 1.1198, Train: 0.2000, Val: 0.1500, Test: 0.3400\n",
      "Epoch: 048, Loss: 1.1107, Train: 0.2163, Val: 0.1500, Test: 0.3400\n",
      "Epoch: 049, Loss: 1.1047, Train: 0.2375, Val: 0.1700, Test: 0.3400\n",
      "Epoch: 050, Loss: 1.1118, Train: 0.2500, Val: 0.1700, Test: 0.3400\n",
      "Epoch: 051, Loss: 1.1141, Train: 0.2662, Val: 0.1700, Test: 0.3400\n",
      "Epoch: 052, Loss: 1.1033, Train: 0.2750, Val: 0.1600, Test: 0.3400\n",
      "Epoch: 053, Loss: 1.0984, Train: 0.2850, Val: 0.1600, Test: 0.3400\n",
      "Epoch: 054, Loss: 1.0974, Train: 0.2962, Val: 0.1500, Test: 0.3400\n",
      "Epoch: 055, Loss: 1.1021, Train: 0.3000, Val: 0.1500, Test: 0.3400\n",
      "Epoch: 056, Loss: 1.0969, Train: 0.3075, Val: 0.1500, Test: 0.3400\n",
      "Epoch: 057, Loss: 1.0851, Train: 0.3200, Val: 0.1400, Test: 0.3400\n",
      "Epoch: 058, Loss: 1.0867, Train: 0.3312, Val: 0.1400, Test: 0.3400\n",
      "Epoch: 059, Loss: 1.0806, Train: 0.3413, Val: 0.1500, Test: 0.3400\n",
      "Epoch: 060, Loss: 1.0907, Train: 0.3512, Val: 0.1500, Test: 0.3400\n",
      "Epoch: 061, Loss: 1.0797, Train: 0.3637, Val: 0.1500, Test: 0.3400\n",
      "Epoch: 062, Loss: 1.0789, Train: 0.3738, Val: 0.1400, Test: 0.3400\n",
      "Epoch: 063, Loss: 1.0711, Train: 0.4000, Val: 0.1600, Test: 0.3400\n",
      "Epoch: 064, Loss: 1.0669, Train: 0.4200, Val: 0.1600, Test: 0.3400\n",
      "Epoch: 065, Loss: 1.0595, Train: 0.4338, Val: 0.1500, Test: 0.3400\n",
      "Epoch: 066, Loss: 1.0597, Train: 0.4500, Val: 0.1800, Test: 0.3400\n",
      "Epoch: 067, Loss: 1.0674, Train: 0.4700, Val: 0.1800, Test: 0.3400\n",
      "Epoch: 068, Loss: 1.0523, Train: 0.4725, Val: 0.1800, Test: 0.3400\n",
      "Epoch: 069, Loss: 1.0584, Train: 0.4725, Val: 0.1800, Test: 0.3400\n",
      "Epoch: 070, Loss: 1.0477, Train: 0.4775, Val: 0.1800, Test: 0.3400\n",
      "Epoch: 071, Loss: 1.0379, Train: 0.4775, Val: 0.2000, Test: 0.3400\n",
      "Epoch: 072, Loss: 1.0366, Train: 0.4875, Val: 0.2100, Test: 0.3400\n",
      "Epoch: 073, Loss: 1.0319, Train: 0.5037, Val: 0.2000, Test: 0.3400\n",
      "Epoch: 074, Loss: 1.0283, Train: 0.5175, Val: 0.2100, Test: 0.3400\n",
      "Epoch: 075, Loss: 1.0256, Train: 0.5662, Val: 0.2100, Test: 0.3400\n",
      "Epoch: 076, Loss: 1.0259, Train: 0.6125, Val: 0.2100, Test: 0.3400\n",
      "Epoch: 077, Loss: 1.0037, Train: 0.6525, Val: 0.2100, Test: 0.3400\n",
      "Epoch: 078, Loss: 1.0143, Train: 0.6712, Val: 0.2300, Test: 0.3400\n",
      "Epoch: 079, Loss: 0.9996, Train: 0.6862, Val: 0.2600, Test: 0.3400\n",
      "Epoch: 080, Loss: 1.0068, Train: 0.7100, Val: 0.2600, Test: 0.3400\n",
      "Epoch: 081, Loss: 1.0038, Train: 0.7225, Val: 0.2700, Test: 0.3400\n",
      "Epoch: 082, Loss: 0.9972, Train: 0.7300, Val: 0.2700, Test: 0.3400\n",
      "Epoch: 083, Loss: 0.9896, Train: 0.7325, Val: 0.2600, Test: 0.3400\n",
      "Epoch: 084, Loss: 0.9814, Train: 0.7500, Val: 0.2700, Test: 0.3400\n",
      "Epoch: 085, Loss: 0.9730, Train: 0.7587, Val: 0.2700, Test: 0.3400\n",
      "Epoch: 086, Loss: 0.9799, Train: 0.7537, Val: 0.2600, Test: 0.3400\n",
      "Epoch: 087, Loss: 0.9766, Train: 0.7375, Val: 0.2700, Test: 0.3400\n",
      "Epoch: 088, Loss: 0.9654, Train: 0.7287, Val: 0.2700, Test: 0.3400\n",
      "Epoch: 089, Loss: 0.9655, Train: 0.7462, Val: 0.2600, Test: 0.3400\n",
      "Epoch: 090, Loss: 0.9604, Train: 0.8112, Val: 0.3200, Test: 0.3400\n",
      "Epoch: 091, Loss: 0.9554, Train: 0.8562, Val: 0.3200, Test: 0.3400\n",
      "Epoch: 092, Loss: 0.9404, Train: 0.8850, Val: 0.3200, Test: 0.3400\n",
      "Epoch: 093, Loss: 0.9321, Train: 0.8950, Val: 0.3500, Test: 0.3400\n",
      "Epoch: 094, Loss: 0.9305, Train: 0.8875, Val: 0.3500, Test: 0.3400\n",
      "Epoch: 095, Loss: 0.9385, Train: 0.8750, Val: 0.3200, Test: 0.3400\n",
      "Epoch: 096, Loss: 0.9250, Train: 0.8637, Val: 0.3000, Test: 0.3400\n",
      "Epoch: 097, Loss: 0.9100, Train: 0.8537, Val: 0.2900, Test: 0.3400\n",
      "Epoch: 098, Loss: 0.9092, Train: 0.8575, Val: 0.3200, Test: 0.3400\n",
      "Epoch: 099, Loss: 0.9135, Train: 0.8687, Val: 0.3400, Test: 0.3400\n",
      "Epoch: 100, Loss: 0.9230, Train: 0.8975, Val: 0.3400, Test: 0.3400\n",
      "Epoch: 101, Loss: 0.9133, Train: 0.9000, Val: 0.3700, Test: 0.3400\n",
      "Epoch: 102, Loss: 0.9073, Train: 0.9038, Val: 0.3300, Test: 0.3400\n",
      "Epoch: 103, Loss: 0.8906, Train: 0.9087, Val: 0.3200, Test: 0.3400\n",
      "Epoch: 104, Loss: 0.8907, Train: 0.9150, Val: 0.3400, Test: 0.3400\n",
      "Epoch: 105, Loss: 0.8850, Train: 0.9137, Val: 0.3400, Test: 0.3400\n",
      "Epoch: 106, Loss: 0.8859, Train: 0.9175, Val: 0.3500, Test: 0.3400\n",
      "Epoch: 107, Loss: 0.8741, Train: 0.9075, Val: 0.3800, Test: 0.3400\n",
      "Epoch: 108, Loss: 0.8767, Train: 0.9112, Val: 0.3500, Test: 0.3400\n",
      "Epoch: 109, Loss: 0.8642, Train: 0.9225, Val: 0.3300, Test: 0.3400\n",
      "Epoch: 110, Loss: 0.8643, Train: 0.9337, Val: 0.3100, Test: 0.3400\n",
      "Epoch: 111, Loss: 0.8584, Train: 0.9375, Val: 0.3400, Test: 0.3400\n",
      "Epoch: 112, Loss: 0.8602, Train: 0.9562, Val: 0.3300, Test: 0.3400\n",
      "Epoch: 113, Loss: 0.8469, Train: 0.9575, Val: 0.3600, Test: 0.3400\n",
      "Epoch: 114, Loss: 0.8428, Train: 0.9537, Val: 0.3600, Test: 0.3400\n",
      "Epoch: 115, Loss: 0.8444, Train: 0.9587, Val: 0.3400, Test: 0.3400\n",
      "Epoch: 116, Loss: 0.8348, Train: 0.9600, Val: 0.3400, Test: 0.3400\n",
      "Epoch: 117, Loss: 0.8431, Train: 0.9575, Val: 0.3400, Test: 0.3400\n",
      "Epoch: 118, Loss: 0.8302, Train: 0.9575, Val: 0.3400, Test: 0.3400\n",
      "Epoch: 119, Loss: 0.8252, Train: 0.9562, Val: 0.3400, Test: 0.3400\n",
      "Epoch: 120, Loss: 0.8329, Train: 0.9587, Val: 0.3400, Test: 0.3400\n",
      "Epoch: 121, Loss: 0.8211, Train: 0.9663, Val: 0.3400, Test: 0.3400\n",
      "Epoch: 122, Loss: 0.8146, Train: 0.9737, Val: 0.3400, Test: 0.3400\n",
      "Epoch: 123, Loss: 0.8153, Train: 0.9800, Val: 0.3500, Test: 0.3400\n",
      "Epoch: 124, Loss: 0.8022, Train: 0.9837, Val: 0.3600, Test: 0.3400\n",
      "Epoch: 125, Loss: 0.8131, Train: 0.9800, Val: 0.3700, Test: 0.3400\n",
      "Epoch: 126, Loss: 0.8124, Train: 0.9812, Val: 0.3700, Test: 0.3400\n",
      "Epoch: 127, Loss: 0.8064, Train: 0.9800, Val: 0.3400, Test: 0.3400\n",
      "Epoch: 128, Loss: 0.8020, Train: 0.9750, Val: 0.3600, Test: 0.3400\n",
      "Epoch: 129, Loss: 0.8012, Train: 0.9762, Val: 0.3500, Test: 0.3400\n",
      "Epoch: 130, Loss: 0.7941, Train: 0.9812, Val: 0.3600, Test: 0.3400\n",
      "Epoch: 131, Loss: 0.7919, Train: 0.9850, Val: 0.3500, Test: 0.3400\n",
      "Epoch: 132, Loss: 0.7809, Train: 0.9850, Val: 0.3600, Test: 0.3400\n",
      "Epoch: 133, Loss: 0.7896, Train: 0.9887, Val: 0.3700, Test: 0.3400\n",
      "Epoch: 134, Loss: 0.7851, Train: 0.9887, Val: 0.3600, Test: 0.3400\n",
      "Epoch: 135, Loss: 0.7864, Train: 0.9875, Val: 0.3700, Test: 0.3400\n",
      "Epoch: 136, Loss: 0.7704, Train: 0.9887, Val: 0.3700, Test: 0.3400\n",
      "Epoch: 137, Loss: 0.7699, Train: 0.9912, Val: 0.3800, Test: 0.3400\n",
      "Epoch: 138, Loss: 0.7755, Train: 0.9925, Val: 0.3600, Test: 0.3400\n",
      "Epoch: 139, Loss: 0.7667, Train: 0.9950, Val: 0.3700, Test: 0.3400\n",
      "Epoch: 140, Loss: 0.7596, Train: 0.9950, Val: 0.3700, Test: 0.3400\n",
      "Epoch: 141, Loss: 0.7599, Train: 0.9950, Val: 0.3500, Test: 0.3400\n",
      "Epoch: 142, Loss: 0.7601, Train: 0.9950, Val: 0.3600, Test: 0.3400\n",
      "Epoch: 143, Loss: 0.7648, Train: 0.9950, Val: 0.3600, Test: 0.3400\n",
      "Epoch: 144, Loss: 0.7483, Train: 0.9950, Val: 0.3200, Test: 0.3400\n",
      "Epoch: 145, Loss: 0.7552, Train: 0.9937, Val: 0.3200, Test: 0.3400\n",
      "Epoch: 146, Loss: 0.7587, Train: 0.9962, Val: 0.3200, Test: 0.3400\n",
      "Epoch: 147, Loss: 0.7514, Train: 0.9962, Val: 0.3500, Test: 0.3400\n",
      "Epoch: 148, Loss: 0.7568, Train: 0.9975, Val: 0.3500, Test: 0.3400\n",
      "Epoch: 149, Loss: 0.7484, Train: 0.9987, Val: 0.3700, Test: 0.3400\n",
      "Epoch: 150, Loss: 0.7423, Train: 0.9975, Val: 0.3700, Test: 0.3400\n",
      "Epoch: 151, Loss: 0.7464, Train: 0.9975, Val: 0.3700, Test: 0.3400\n",
      "Epoch: 152, Loss: 0.7411, Train: 0.9987, Val: 0.3600, Test: 0.3400\n",
      "Epoch: 153, Loss: 0.7419, Train: 0.9987, Val: 0.3500, Test: 0.3400\n",
      "Epoch: 154, Loss: 0.7440, Train: 0.9987, Val: 0.3400, Test: 0.3400\n",
      "Epoch: 155, Loss: 0.7431, Train: 0.9987, Val: 0.3300, Test: 0.3400\n",
      "Epoch: 156, Loss: 0.7424, Train: 1.0000, Val: 0.3400, Test: 0.3400\n",
      "Epoch: 157, Loss: 0.7434, Train: 1.0000, Val: 0.3300, Test: 0.3400\n",
      "Epoch: 158, Loss: 0.7292, Train: 1.0000, Val: 0.3300, Test: 0.3400\n",
      "Epoch: 159, Loss: 0.7348, Train: 1.0000, Val: 0.3600, Test: 0.3400\n",
      "Epoch: 160, Loss: 0.7340, Train: 1.0000, Val: 0.3800, Test: 0.3400\n",
      "Epoch: 161, Loss: 0.7356, Train: 0.9987, Val: 0.3900, Test: 0.3400\n",
      "Epoch: 162, Loss: 0.7331, Train: 0.9987, Val: 0.4200, Test: 0.3800\n",
      "Epoch: 163, Loss: 0.7309, Train: 0.9987, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 164, Loss: 0.7332, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 165, Loss: 0.7213, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 166, Loss: 0.7182, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 167, Loss: 0.7334, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 168, Loss: 0.7305, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 169, Loss: 0.7192, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 170, Loss: 0.7292, Train: 0.9987, Val: 0.4200, Test: 0.3800\n",
      "Epoch: 171, Loss: 0.7371, Train: 1.0000, Val: 0.4200, Test: 0.3800\n",
      "Epoch: 172, Loss: 0.7187, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 173, Loss: 0.7117, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 174, Loss: 0.7217, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 175, Loss: 0.7156, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 176, Loss: 0.7331, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 177, Loss: 0.7148, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 178, Loss: 0.7101, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 179, Loss: 0.7195, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 180, Loss: 0.7116, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 181, Loss: 0.7151, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 182, Loss: 0.7112, Train: 1.0000, Val: 0.4000, Test: 0.3800\n",
      "Epoch: 183, Loss: 0.7083, Train: 1.0000, Val: 0.4000, Test: 0.3800\n",
      "Epoch: 184, Loss: 0.7095, Train: 1.0000, Val: 0.4000, Test: 0.3800\n",
      "Epoch: 185, Loss: 0.7070, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 186, Loss: 0.7196, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 187, Loss: 0.7061, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 188, Loss: 0.7005, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 189, Loss: 0.7088, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 190, Loss: 0.7035, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 191, Loss: 0.7155, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 192, Loss: 0.7030, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 193, Loss: 0.7124, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 194, Loss: 0.7017, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 195, Loss: 0.7028, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 196, Loss: 0.7026, Train: 1.0000, Val: 0.4000, Test: 0.3800\n",
      "Epoch: 197, Loss: 0.7008, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 198, Loss: 0.7037, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 199, Loss: 0.7004, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 200, Loss: 0.7046, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 201, Loss: 0.6998, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 202, Loss: 0.7057, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 203, Loss: 0.7010, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 204, Loss: 0.7022, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 205, Loss: 0.6979, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 206, Loss: 0.7024, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 207, Loss: 0.7068, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 208, Loss: 0.6959, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 209, Loss: 0.6964, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 210, Loss: 0.7039, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 211, Loss: 0.7004, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 212, Loss: 0.6941, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 213, Loss: 0.6937, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 214, Loss: 0.6952, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 215, Loss: 0.6927, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 216, Loss: 0.6912, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 217, Loss: 0.6892, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 218, Loss: 0.6944, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 219, Loss: 0.6954, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 220, Loss: 0.6931, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 221, Loss: 0.7030, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 222, Loss: 0.6951, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 223, Loss: 0.6898, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 224, Loss: 0.6892, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 225, Loss: 0.6911, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 226, Loss: 0.6920, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 227, Loss: 0.6860, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 228, Loss: 0.6919, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 229, Loss: 0.6905, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 230, Loss: 0.6982, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 231, Loss: 0.6866, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 232, Loss: 0.6958, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 233, Loss: 0.6898, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 234, Loss: 0.6852, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 235, Loss: 0.6833, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 236, Loss: 0.6921, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 237, Loss: 0.6872, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 238, Loss: 0.6870, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 239, Loss: 0.6812, Train: 1.0000, Val: 0.4100, Test: 0.3800\n",
      "Epoch: 240, Loss: 0.6898, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 241, Loss: 0.6870, Train: 1.0000, Val: 0.4000, Test: 0.3800\n",
      "Epoch: 242, Loss: 0.6850, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 243, Loss: 0.6844, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 244, Loss: 0.6927, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 245, Loss: 0.6888, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 246, Loss: 0.6920, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 247, Loss: 0.6909, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 248, Loss: 0.6801, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 249, Loss: 0.6829, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 250, Loss: 0.6826, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 251, Loss: 0.6802, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 252, Loss: 0.6801, Train: 1.0000, Val: 0.4000, Test: 0.3800\n",
      "Epoch: 253, Loss: 0.6789, Train: 1.0000, Val: 0.4000, Test: 0.3800\n",
      "Epoch: 254, Loss: 0.6828, Train: 1.0000, Val: 0.4000, Test: 0.3800\n",
      "Epoch: 255, Loss: 0.6888, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 256, Loss: 0.6899, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 257, Loss: 0.6823, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 258, Loss: 0.6869, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 259, Loss: 0.6881, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 260, Loss: 0.6840, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 261, Loss: 0.6788, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 262, Loss: 0.6810, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 263, Loss: 0.6854, Train: 1.0000, Val: 0.4100, Test: 0.3800\n",
      "Epoch: 264, Loss: 0.6799, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 265, Loss: 0.6789, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 266, Loss: 0.6749, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 267, Loss: 0.6914, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 268, Loss: 0.6774, Train: 1.0000, Val: 0.4000, Test: 0.3800\n",
      "Epoch: 269, Loss: 0.6822, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 270, Loss: 0.6812, Train: 1.0000, Val: 0.4000, Test: 0.3800\n",
      "Epoch: 271, Loss: 0.6784, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 272, Loss: 0.6795, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 273, Loss: 0.6871, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 274, Loss: 0.6782, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 275, Loss: 0.6814, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 276, Loss: 0.6802, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 277, Loss: 0.6767, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 278, Loss: 0.6763, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 279, Loss: 0.6813, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 280, Loss: 0.6826, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 281, Loss: 0.6741, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 282, Loss: 0.6758, Train: 1.0000, Val: 0.4000, Test: 0.3800\n",
      "Epoch: 283, Loss: 0.6810, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 284, Loss: 0.6758, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 285, Loss: 0.6764, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 286, Loss: 0.6798, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 287, Loss: 0.6758, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 288, Loss: 0.6786, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 289, Loss: 0.6805, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 290, Loss: 0.6805, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 291, Loss: 0.6817, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 292, Loss: 0.6776, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 293, Loss: 0.6765, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 294, Loss: 0.6726, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 295, Loss: 0.6785, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 296, Loss: 0.6797, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 297, Loss: 0.6809, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 298, Loss: 0.6722, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 299, Loss: 0.6798, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 300, Loss: 0.6730, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 301, Loss: 0.6775, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 302, Loss: 0.6761, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 303, Loss: 0.6769, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 304, Loss: 0.6774, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 305, Loss: 0.6810, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 306, Loss: 0.6781, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 307, Loss: 0.6691, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 308, Loss: 0.6741, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 309, Loss: 0.6762, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 310, Loss: 0.6778, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 311, Loss: 0.6693, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 312, Loss: 0.6799, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 313, Loss: 0.6767, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 314, Loss: 0.6750, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 315, Loss: 0.6784, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 316, Loss: 0.6807, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 317, Loss: 0.6809, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 318, Loss: 0.6755, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 319, Loss: 0.6705, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 320, Loss: 0.6743, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 321, Loss: 0.6753, Train: 1.0000, Val: 0.4000, Test: 0.3800\n",
      "Epoch: 322, Loss: 0.6761, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 323, Loss: 0.6738, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 324, Loss: 0.6690, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 325, Loss: 0.6758, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 326, Loss: 0.6812, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 327, Loss: 0.6724, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 328, Loss: 0.6778, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 329, Loss: 0.6709, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 330, Loss: 0.6688, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 331, Loss: 0.6706, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 332, Loss: 0.6786, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 333, Loss: 0.6741, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 334, Loss: 0.6713, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 335, Loss: 0.6726, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 336, Loss: 0.6691, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 337, Loss: 0.6715, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 338, Loss: 0.6701, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 339, Loss: 0.6739, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 340, Loss: 0.6678, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 341, Loss: 0.6708, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 342, Loss: 0.6721, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 343, Loss: 0.6752, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 344, Loss: 0.6722, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 345, Loss: 0.6761, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 346, Loss: 0.6697, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 347, Loss: 0.6709, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 348, Loss: 0.6781, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 349, Loss: 0.6711, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 350, Loss: 0.6721, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 351, Loss: 0.6714, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 352, Loss: 0.6676, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 353, Loss: 0.6717, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 354, Loss: 0.6706, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 355, Loss: 0.6728, Train: 1.0000, Val: 0.3900, Test: 0.3800\n",
      "Epoch: 356, Loss: 0.6738, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 357, Loss: 0.6665, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 358, Loss: 0.6747, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 359, Loss: 0.6668, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 360, Loss: 0.6699, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 361, Loss: 0.6715, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 362, Loss: 0.6680, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 363, Loss: 0.6694, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 364, Loss: 0.6726, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 365, Loss: 0.6703, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 366, Loss: 0.6741, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 367, Loss: 0.6704, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 368, Loss: 0.6691, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 369, Loss: 0.6652, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 370, Loss: 0.6695, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 371, Loss: 0.6714, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 372, Loss: 0.6714, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 373, Loss: 0.6802, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 374, Loss: 0.6725, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 375, Loss: 0.6760, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 376, Loss: 0.6704, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 377, Loss: 0.6659, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 378, Loss: 0.6684, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 379, Loss: 0.6676, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 380, Loss: 0.6717, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 381, Loss: 0.6693, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 382, Loss: 0.6637, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 383, Loss: 0.6696, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 384, Loss: 0.6736, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 385, Loss: 0.6723, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 386, Loss: 0.6702, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 387, Loss: 0.6724, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 388, Loss: 0.6682, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 389, Loss: 0.6655, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 390, Loss: 0.6650, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 391, Loss: 0.6694, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 392, Loss: 0.6708, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 393, Loss: 0.6696, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 394, Loss: 0.6663, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 395, Loss: 0.6649, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 396, Loss: 0.6651, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 397, Loss: 0.6652, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 398, Loss: 0.6662, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 399, Loss: 0.6696, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 400, Loss: 0.6667, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 401, Loss: 0.6713, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 402, Loss: 0.6640, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 403, Loss: 0.6652, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 404, Loss: 0.6601, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 405, Loss: 0.6681, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 406, Loss: 0.6655, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 407, Loss: 0.6640, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 408, Loss: 0.6698, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 409, Loss: 0.6650, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 410, Loss: 0.6642, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 411, Loss: 0.6654, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 412, Loss: 0.6676, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 413, Loss: 0.6711, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 414, Loss: 0.6680, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 415, Loss: 0.6643, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 416, Loss: 0.6655, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 417, Loss: 0.6680, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 418, Loss: 0.6680, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 419, Loss: 0.6623, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 420, Loss: 0.6642, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 421, Loss: 0.6661, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 422, Loss: 0.6672, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 423, Loss: 0.6669, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 424, Loss: 0.6607, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 425, Loss: 0.6658, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 426, Loss: 0.6657, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 427, Loss: 0.6684, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 428, Loss: 0.6637, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 429, Loss: 0.6656, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 430, Loss: 0.6680, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 431, Loss: 0.6713, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 432, Loss: 0.6631, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 433, Loss: 0.6643, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 434, Loss: 0.6601, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 435, Loss: 0.6662, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 436, Loss: 0.6641, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 437, Loss: 0.6624, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 438, Loss: 0.6660, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 439, Loss: 0.6691, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 440, Loss: 0.6654, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 441, Loss: 0.6682, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 442, Loss: 0.6651, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 443, Loss: 0.6634, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 444, Loss: 0.6692, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 445, Loss: 0.6624, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 446, Loss: 0.6611, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 447, Loss: 0.6601, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 448, Loss: 0.6621, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 449, Loss: 0.6651, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 450, Loss: 0.6648, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 451, Loss: 0.6649, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 452, Loss: 0.6688, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 453, Loss: 0.6636, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 454, Loss: 0.6677, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 455, Loss: 0.6629, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 456, Loss: 0.6647, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 457, Loss: 0.6670, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 458, Loss: 0.6606, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 459, Loss: 0.6625, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 460, Loss: 0.6612, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 461, Loss: 0.6654, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 462, Loss: 0.6583, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 463, Loss: 0.6607, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 464, Loss: 0.6644, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 465, Loss: 0.6595, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 466, Loss: 0.6629, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 467, Loss: 0.6672, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 468, Loss: 0.6603, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 469, Loss: 0.6599, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 470, Loss: 0.6701, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 471, Loss: 0.6612, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 472, Loss: 0.6618, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 473, Loss: 0.6633, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 474, Loss: 0.6642, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 475, Loss: 0.6583, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 476, Loss: 0.6635, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 477, Loss: 0.6616, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 478, Loss: 0.6606, Train: 1.0000, Val: 0.3700, Test: 0.3800\n",
      "Epoch: 479, Loss: 0.6610, Train: 1.0000, Val: 0.3800, Test: 0.3800\n",
      "Epoch: 480, Loss: 0.6582, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 481, Loss: 0.6619, Train: 1.0000, Val: 0.3500, Test: 0.3800\n",
      "Epoch: 482, Loss: 0.6581, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 483, Loss: 0.6593, Train: 1.0000, Val: 0.3100, Test: 0.3800\n",
      "Epoch: 484, Loss: 0.6648, Train: 1.0000, Val: 0.3000, Test: 0.3800\n",
      "Epoch: 485, Loss: 0.6603, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 486, Loss: 0.6635, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 487, Loss: 0.6631, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 488, Loss: 0.6615, Train: 1.0000, Val: 0.3600, Test: 0.3800\n",
      "Epoch: 489, Loss: 0.6670, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 490, Loss: 0.6640, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 491, Loss: 0.6603, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 492, Loss: 0.6671, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 493, Loss: 0.6632, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 494, Loss: 0.6593, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 495, Loss: 0.6599, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 496, Loss: 0.6587, Train: 1.0000, Val: 0.3400, Test: 0.3800\n",
      "Epoch: 497, Loss: 0.6631, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 498, Loss: 0.6613, Train: 1.0000, Val: 0.3200, Test: 0.3800\n",
      "Epoch: 499, Loss: 0.6630, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Epoch: 500, Loss: 0.6565, Train: 1.0000, Val: 0.3300, Test: 0.3800\n",
      "Median time per epoch: 0.0920s\n"
     ]
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.num_lin = Linear(1, embed_dim)\n",
    "        self.conv1 = RGCNConv(embed_dim, 32, data.num_relations,\n",
    "                          num_bases=30)\n",
    "        self.conv2 = RGCNConv(32, 32, data.num_relations,\n",
    "                          num_bases=30)\n",
    "        # self.conv3 = RGCNConv(16, 16, data.num_relations,\n",
    "        #                   num_bases=4)\n",
    "        self.conv4 = RGCNConv(32, data.num_classes, data.num_relations,\n",
    "                          num_bases=30)\n",
    "\n",
    "    def forward(self, edge_index, edge_type):\n",
    "        x = F.relu(self.num_lin(data.num_x))\n",
    "        x = x + data.x\n",
    "        x = F.relu(self.conv1(data.x, edge_index, edge_type))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index, edge_type))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # x = F.relu(self.conv3(x, edge_index, edge_type))\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        x = self.conv4(x, edge_index, edge_type)\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model, data = Net().to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.edge_index, data.edge_type)\n",
    "    loss = F.cross_entropy(out[data.train_idx], data.train_y, weight=torch.Tensor(class_weight).to(device), label_smoothing=0.2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    pred = model(data.edge_index, data.edge_type).argmax(dim=-1)\n",
    "    train_acc = float((pred[data.train_idx] == data.train_y).float().mean())\n",
    "    val_acc = float((pred[data.valid_idx] == data.valid_y).float().mean())\n",
    "    test_acc = float((pred[data.test_idx] == data.test_y).float().mean())\n",
    "    return train_acc, val_acc, test_acc\n",
    "\n",
    "times = []\n",
    "best_val_acc = final_test_acc = 0\n",
    "for epoch in range(1, 501):\n",
    "    start = time.time()\n",
    "    loss = train()\n",
    "    train_acc, val_acc, tmp_test_acc = test()\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        test_acc = tmp_test_acc\n",
    "        torch.save(model.state_dict(), f'processed_data/model_weights_rgcn_{num_patients}.pth')\n",
    "    log(Epoch=epoch, Loss=loss, Train=train_acc, Val=val_acc, Test=test_acc)\n",
    "    times.append(time.time() - start)\n",
    "print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results - AUC / Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.5266\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load(f'processed_data/model_weights_rgcn_{num_patients}.pth', weights_only=True))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(data.edge_index, data.edge_type).cpu()\n",
    "    prob = F.softmax(out, dim=1)\n",
    "auc = roc_auc_score(data.test_y.cpu(), prob[data.test_idx.cpu()], multi_class='ovr')\n",
    "print(f'ROC AUC score: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0    46\n",
      "1    43\n",
      "2    11\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAG2CAYAAACXuTmvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABM60lEQVR4nO3deVxU5f4H8M9hG7ZhkB2EAAF3Rc3lornlhpZ7i167F8zsVqKpgVquaMbN9OdSaqYJaZqZqeUSXaUE99TE0swERTBRywUclG3m+f1BTI44yjADM8583q/XeeXZnvOdJfjyfZ7nHEkIIUBERERkRWxMHQARERFRXWMCRERERFaHCRARERFZHSZAREREZHWYABEREZHVYQJEREREVocJEBEREVkdJkBERERkdZgAERERkdVhAkRERERWhwkQERERmY2kpCS0a9cOcrkcPj4+GDRoEM6cOaN1TLdu3SBJktbyyiuv6HUdJkBERERkNtLT0zFmzBgcOnQIu3btQllZGXr37o2ioiKt40aPHo38/HzNMm/ePL2uY2fMoImIiIgMkZqaqrWekpICHx8fHDt2DF26dNFsd3Z2hp+fX42vwwTISqnValy6dAlyuRySJJk6HCIi0oMQArdu3UJAQABsbGqvM6e4uBilpaVGaUsIUeX3jUwmg0wme+B5BQUFAAAPDw+t7evWrcOnn34KPz8/9O/fH9OnT4ezs3O145GEEKLaR5PFuHjxIoKCgkwdBhERGSAvLw+BgYG10nZxcTFCg11x+arKKO25urpCqVRqbZs5cyZmzZql8xy1Wo0BAwbg5s2b2Ldvn2b7Rx99hODgYAQEBOCnn37C5MmT0b59e2zevLna8bACZKXkcjkAoEnyWNg6Pzj7pkff3tbV/6FAj75ne0abOgSqZeXqUuy5uErzs7w2lJaW4vJVFS4cC4Gb3LAqU+EtNYIfz0FeXh7c3Nw02x9W/RkzZgxOnjyplfwAwMsvv6z5d4sWLeDv748ePXogOzsbYWFh1YqJCZCVqixD2jrLmABZAUN/eNGjxc6G/09bi7oYwuAql+AqN+w6alSc7+bmppUAPUhcXBy2b9+OjIyMh1a5OnToAADIyspiAkRERESGUwk1VAYOllEJdbWPFUJg7Nix2LJlC/bs2YPQ0NCHnpOZmQkA8Pf3r/Z1mAARERGRTmoIqGFYBqTP+WPGjMH69evx1VdfQS6X4/LlywAAhUIBJycnZGdnY/369ejXrx88PT3x008/YcKECejSpQtatmxZ7eswASIiIiKzsXz5cgAVNzu8W3JyMmJjY+Hg4IDdu3dj0aJFKCoqQlBQEIYOHYpp06bpdR0mQERERKSTGmpUvwNLdxvV9bDJ6UFBQUhPTzcwIiZARERE9AAqIaAy8I45hp5fGzg1hIiIiKwOK0BERESkU10Pgq4rTICIiIhIJzUEVBaYALELjIiIiKwOK0BERESkE7vAiIiIyOpwFhgRERGRhWAFiIiIiHRS/7UY2oa5YQJEREREOqmMMAvM0PNrAxMgIiIi0kklYISnwRsnFmPiGCAiIiKyOqwAERERkU4cA0RERERWRw0JKkgGt2Fu2AVGREREVocVICIiItJJLSoWQ9swN0yAiIiISCeVEbrADD2/NrALjIiIiKwOK0BERESkk6VWgJgAERERkU5qIUEtDJwFZuD5tYFdYERERGR1WAEiIiIindgFRkRERFZHBRuoDOwwUhkpFmNiAkREREQ6CSOMARIcA0RERERkeqwAERERkU4cA0RERERWRyVsoBIGjgEyw0dhsAuMiIiIrA4rQERERKSTGhLUBtZL1DC/EhATICIiItLJUscAsQuMiIiIrA4rQERERKSTcQZBswuMiIiIHiEVY4AMfBgqu8CIiIiITI8VICIiItJJbYRngXEWGBERET1SOAaIiIiIrI4aNhZ5HyCOASIiIiKrwwoQERER6aQSElTCwBshGnh+bWACRERERDqpjDAIWsUuMCIiIiLTYwWIiIiIdFILG6gNnAWm5iwwIiIiepSwC4yIiIjIQrACRERERDqpYfgsLrVxQjEqJkBERESkk3FuhGh+HU7mFxERERFRLWMFiIiIiHQyzrPAzK/ewgSIiIiIdFJDghqGjgHinaCJap39ydtw2nIddtnFsL2uQsFbASj9h1yz33vAmfuep4z1xp0hHnUVJhnBhvd9sH+nO/KyZHBwVKNp29sYNfUSgsJLNMckDA3HTwddtc7r968/8fq7F+s6XKpFz/4rC7Gv/Yqtn4di5aJmpg7HorACZCFCQkIwfvx4jB8/3tShUC2RStQoD5WhuKcCiqRLVfb/+UmY1rrDsSLI37+Mko6uVY4l8/bTQVf0j/0TDVvdhqocSPmvP94aHoaV6b/C0fnveSd9R/yJfydc1qzLnMxxTgrVVESTm4gedAHnzsoffjDRX8wqJYuNjYUkSZrF09MT0dHR+Omnn+oshqSkJLRr1w5yuRw+Pj4YNGgQzpzRrhiEhIRg0aJFVc6dNWsWWrVqVTeBkk6lj7vi9gveKI26/w9DUc9Oa5EdVqKshTPUfg51HCkZ6p3159D7+esIaVSMsGbFeGNRLq7+7oCzPzlpHSdzEvDwKdcsLnImQJbC0akcCbOO4/3/toTylr2pw7FIlTdCNHQxN2YXUXR0NPLz85Gfn4+0tDTY2dnh6aefrrPrp6enY8yYMTh06BB27dqFsrIy9O7dG0VFRXUWA9Ud6UY5HI4qUdxLYepQyAiKCm0BAHJ3ldb27zfXw7PNmuPl7o2w+h1/FN82v/EIVDOvxp/EkQM+yDzibepQLJZaSEZZzI3ZJUAymQx+fn7w8/NDq1atMGXKFOTl5eGPP/4AAEyePBkNGzaEs7MzGjRogOnTp6OsrEyrjW3btqFdu3ZwdHSEl5cXBg8erPN6q1atgru7O9LS0gAAqampiI2NRbNmzRAZGYmUlBTk5ubi2LFjer8WtVqN2bNnIzAwEDKZDK1atUJqaqpmf05ODiRJwsaNG9G5c2c4OTmhXbt2+O2333DkyBG0bdsWrq6u6Nu3r+b13x13kyZN4OjoiMaNG2PZsmV6x0eA43cFEE42KIli99ejTq0GPpxZH83aKRHSuFizvfvgG5j0wQXM25SFYWOvIu3Lepg3NtiEkZKxdOn5O8IbFSBleWNTh0KPILMeA6RUKvHpp58iPDwcnp6eAAC5XI6UlBQEBATg559/xujRoyGXyzFp0iQAwI4dOzB48GBMnToVa9asQWlpKXbu3Hnf9ufNm4d58+bhf//7H9q3b3/fYwoKCgAAHh76D45dvHgxFixYgBUrVqB169ZYvXo1BgwYgFOnTiEiIkJz3MyZM7Fo0SI89thjePHFF/HPf/4TcrkcixcvhrOzM5577jnMmDEDy5cvBwCsW7cOM2bMwAcffIDWrVvj+PHjGD16NFxcXBATE3PfWEpKSlBS8vfA0MLCQr1fjyVy3F2Ikq5ugIPZ/S1AevrgrUBc+NUJC7ae1dre74Vrmn+HNimGh08ZJj8Xjks5DggIKa3rMMlIvHzu4OUJpzBt3D9QVmpr6nAsmtoIXVjmeCNEs0uAtm/fDlfXir/Gi4qK4O/vj+3bt8PGpuLNmzZtmubYkJAQxMfHY8OGDZoEaO7cuRg2bBgSExM1x0VGRla5zuTJk7F27Vqkp6ejWbP7zxhQq9UYP348OnXqhObNm1c5/+5YAKC0tBRNmzbVrM+fPx+TJ0/GsGHDAADvvvsuvv/+eyxatAhLly7VHBcfH48+ffoAAF5//XUMHz4caWlp6NSpEwBg1KhRSElJ0Rw/c+ZMLFiwAEOGDAEAhIaG4pdffsGKFSt0JkBJSUla7wkB9qduw+73UhRO8jd1KGSgD96qj8O73LBgSxa8A8oeeGzjNrcBAJdyZEyAHmHhjQtQz6MUS1L2arbZ2gk0b3Ud/YfmYFDXflCrza/b5VFknKfBMwF6qO7du2sqHTdu3MCyZcvQt29f/PDDDwgODsbnn3+OJUuWIDs7G0qlEuXl5XBzc9Ocn5mZidGjRz/wGgsWLEBRURGOHj2KBg0a6DxuzJgxOHnyJPbt21dlX0JCAmJjY7W2LVmyBBkZGQAqKiyXLl3SJDGVOnXqhBMnTmhta9mypebfvr6+AIAWLVpobbt69SqAiqQwOzsbo0aN0nqd5eXlUCh0j2N58803MXHiRM16YWEhgoKCdB5vDRx3FaAsXAZVqKOpQ6EaEgJYOrU+DqQq8N6mLPg99vCEJvtkxQBpD58HJ0pk3k4c9cJrI7pobRs/9QQuXnDFpk/DmPzQQ5ldAuTi4oLw8HDN+qpVq6BQKLBy5Uo89dRTGDFiBBITE9GnTx8oFAps2LABCxYs0Bzv5OR0v2a1dO7cGTt27MDGjRsxZcqU+x4TFxeH7du3IyMjA4GBgVX2e3l5acUJ1KybDADs7f+euSBJ0n23qdUVs1aUSiUAYOXKlejQoYNWO7a2usvAMpkMMpmsRvE9cu6oYZv/9y9C2ytlsD1XDCG3hdq74n2Vbqsg238Lyhd9TBUlGcEHbwXi+y31MCv5HJxc1bh+teJHmotcBZmTwKUcB3y/pR7a9yiEvJ4K539xxIpZ9dHiH0o0aFr8kNbJnN25bYcL59y0thUX26Kw0KHKdjKMChJUBt7I0NDza4PZJUD3kiQJNjY2uHPnDg4cOIDg4GBMnTpVs//ChQtax7ds2RJpaWkYOXKkzjbbt2+PuLg4REdHw87ODvHx8Zp9QgiMHTsWW7ZswZ49exAaGlqjuN3c3BAQEID9+/eja9eumu379+/XOd6oOnx9fREQEIBz585hxIgRNW7HktlnFcN9ap5m3fXjigHkxU+64db4iu4uWcYtQAAlXXjfkEfZ9k+8AAAJQyO0tr+xMBe9n78OO3uB43vl2LLKG8W3beAdUIYn+t3E8PFXTBEu0SOJXWB1pKSkBJcvV9yw7MaNG/jggw+gVCrRv39/FBYWIjc3Fxs2bEC7du2wY8cObNmyRev8mTNnokePHggLC8OwYcNQXl6OnTt3YvLkyVrHdezYETt37kTfvn1hZ2enuTHimDFjsH79enz11VeQy+WaWBQKRbWqS3dLSEjAzJkzERYWhlatWiE5ORmZmZlYt25dDd+dComJiRg3bhwUCgWio6NRUlKCo0eP4saNG1rdXNaqrIUz/vi60QOPKY52R3G0e90ERLXm20uZD9zvU78M8zdn1U0wZHJvjulo6hDoEWJ2CVBqair8/Sv+SpfL5WjcuDG++OILdOvWDQAwYcIExMXFoaSkBE899RSmT5+OWbNmac7v1q0bvvjiC8yZMwf//e9/4ebmhi5dutznSsATTzyBHTt2oF+/frC1tcXYsWM1448qr1cpOTm5ypifhxk3bhwKCgrwxhtv4OrVq2jatCm+/vprrRlgNfHSSy/B2dkZ7733HhISEuDi4oIWLVrw7tZERGR0KhjehaV6+CF1ThJCCFMHQXWvsLAQCoUCzT+Ph62zlYwNsmI/tv3c1CFQHXoqqr+pQ6BaVq4uwe7cZSgoKNCaCGRMlb8nph3qDUdXw+6yXawsw9v/+F+txqsvs6sAERERkfmw1Iehml9ERERERLWMFSAiIiLSSUCC2sAxQILT4ImIiOhRwi4wIiIiIgvBChARERHppBYS1MKwLixDz68NTICIiIhIJ5URngZv6Pm1wfwiIiIiIquVlJSEdu3aQS6Xw8fHB4MGDcKZM2e0jikuLsaYMWPg6ekJV1dXDB06FFeu6PeIGyZAREREpFNlF5ihS3Wlp6djzJgxOHToEHbt2oWysjL07t0bRUVFmmMmTJiAbdu24YsvvkB6ejouXbqEIUOG6PW62AVGREREOqlhA7WB9RJ9zk9NTdVaT0lJgY+PD44dO4YuXbqgoKAAH3/8MdavX48nn3wSQMXjqpo0aYJDhw7hH//4R7WuwwoQERER1YnCwkKtpaSk5KHnFBQUAAA8PDwAAMeOHUNZWRl69uypOaZx48Z47LHHcPDgwWrHwgSIiIiIdFIJySgLAAQFBUGhUGiWpKSkB15brVZj/Pjx6NSpE5o3bw4AuHz5MhwcHODu7q51rK+vLy5fvlzt18UuMCIiItLJmNPg8/LytB6GKpM9+GHcY8aMwcmTJ7Fv3z6Drn8/TICIiIhIJyFsoDbwTs7ir/Pd3Nyq/TT4uLg4bN++HRkZGQgMDNRs9/PzQ2lpKW7evKlVBbpy5Qr8/PyqHRO7wIiIiMhsCCEQFxeHLVu24LvvvkNoaKjW/scffxz29vZIS0vTbDtz5gxyc3MRFRVV7euwAkREREQ6qSBBZeDDTPU5f8yYMVi/fj2++uoryOVyzbgehUIBJycnKBQKjBo1ChMnToSHhwfc3NwwduxYREVFVXsGGMAEiIiIiB5ALQx/lIVaVP/Y5cuXAwC6deumtT05ORmxsbEAgIULF8LGxgZDhw5FSUkJ+vTpg2XLlukVExMgIiIiMhtCPDxbcnR0xNKlS7F06dIaX4cJEBEREemkNsIgaEPPrw1MgIiIiEgnNSSoDRwDZOj5tcH8UjIiIiKiWsYKEBEREel0952cDWnD3DABIiIiIp0sdQyQ+UVEREREVMtYASIiIiKd1DDCs8DMcBA0EyAiIiLSSRhhFphgAkRERESPEmM+Dd6ccAwQERERWR1WgIiIiEgnS50FxgSIiIiIdGIXGBEREZGFYAWIiIiIdLLUZ4ExASIiIiKd2AVGREREZCFYASIiIiKdLLUCxASIiIiIdLLUBIhdYERERGR1WAEiIiIinSy1AsQEiIiIiHQSMHwauzBOKEbFBIiIiIh0stQKEMcAERERkdVhBYiIiIh0stQKEBMgIiIi0slSEyB2gREREZHVYQWIiIiIdLLUChATICIiItJJCAnCwATG0PNrA7vAiIiIyOqwAkREREQ6qSEZfCNEQ8+vDUyAiIiISCdLHQPELjAiIiKyOqwAERERkU6WOgiaCRARERHpZKldYEyAiIiISCdLrQBxDBARERFZHVaArFzRbQfYQGbqMKiW9Trd39QhUB0q7Bpo6hColqlKi4HcurmWMEIXmDlWgJgAERERkU4CgBCGt2Fu2AVGREREVocVICIiItJJDQkS7wRNRERE1oSzwIiIiIgsBCtAREREpJNaSJB4I0QiIiKyJkIYYRaYGU4DYxcYERERWR1WgIiIiEgnSx0EzQSIiIiIdGICRERERFbHUgdBcwwQERERWR1WgIiIiEgnS50FxgSIiIiIdKpIgAwdA2SkYIyIXWBERERkdVgBIiIiIp04C4yIiIisjvhrMbQNc8MuMCIiIrI6rAARERGRTuwCIyIiIutjoX1gTICIiIhINyNUgGCGFSCOASIiIiKrwwoQERER6cQ7QRMREZHVsdRB0OwCIyIiIqvDChARERHpJiTDBzGbYQWICRARERHpZKljgNgFRkRERFaHFSAiIiLSzZpvhPj1119Xu8EBAwbUOBgiIiIyL5Y6C6xaCdCgQYOq1ZgkSVCpVIbEQ0RERFTrqpUAqdXq2o6DiIiIzJUZdmEZyqAxQMXFxXB0dDRWLERERGRmLLULTO9ZYCqVCnPmzEH9+vXh6uqKc+fOAQCmT5+Ojz/+2OgBEhERkQkJIy16yMjIQP/+/REQEABJkrB161at/bGxsZAkSWuJjo7W6xp6J0Bz585FSkoK5s2bBwcHB8325s2bY9WqVfo2R0RERKSlqKgIkZGRWLp0qc5joqOjkZ+fr1k+++wzva6hdxfYmjVr8NFHH6FHjx545ZVXNNsjIyPx66+/6tscERERmTXpr8XQNqqvb9++6Nu37wOPkclk8PPzq3FEeleAfv/9d4SHh1fZrlarUVZWVuNAiIiIyAwZsQussLBQaykpKalxWHv27IGPjw8aNWqEV199FdeuXdPrfL0ToKZNm2Lv3r1Vtm/atAmtW7fWtzkiIiKyEkFBQVAoFJolKSmpRu1ER0djzZo1SEtLw7vvvov09HT07dtXr1vx6N0FNmPGDMTExOD333+HWq3G5s2bcebMGaxZswbbt2/XtzkiIiIyZ0a8E3ReXh7c3Nw0m2UyWY2aGzZsmObfLVq0QMuWLREWFoY9e/agR48e1WpD7wrQwIEDsW3bNuzevRsuLi6YMWMGTp8+jW3btqFXr176NkdERETmrPJp8IYuANzc3LSWmiZA92rQoAG8vLyQlZVV7XNqdB+gzp07Y9euXTU5lYiIiMioLl68iGvXrsHf37/a59T4RohHjx7F6dOnAVSMC3r88cdr2hQRERGZKSEqFkPb0IdSqdSq5pw/fx6ZmZnw8PCAh4cHEhMTMXToUPj5+SE7OxuTJk1CeHg4+vTpU+1r6J0AXbx4EcOHD8f+/fvh7u4OALh58yY6duyIDRs2IDAwUN8miYiIyFyZ4GnwR48eRffu3TXrEydOBADExMRg+fLl+Omnn/DJJ5/g5s2bCAgIQO/evTFnzhy9utT0ToBeeukllJWV4fTp02jUqBEA4MyZMxg5ciReeuklpKam6tskERERkUa3bt0gHlA2+vbbbw2+ht4JUHp6Og4cOKBJfgCgUaNGeP/999G5c2eDAyIiIiIzctcgZoPaMDN6J0BBQUH3veGhSqVCQECAUYIiIiIi8yCJisXQNsyN3tPg33vvPYwdOxZHjx7VbDt69Chef/11zJ8/36jBERERkYmZ4GGodaFaFaB69epBkv4uXxUVFaFDhw6ws6s4vby8HHZ2dnjxxRcxaNCgWgmUiIiIyFiqlQAtWrSolsMgIiIis2TNY4BiYmJqOw4iIiIyRyaYBl8XanwjRAAoLi5GaWmp1ra7n/FBREREZI70HgRdVFSEuLg4+Pj4wMXFBfXq1dNaiIiIyIJY6CBovROgSZMm4bvvvsPy5cshk8mwatUqJCYmIiAgAGvWrKmNGImIiMhULDQB0rsLbNu2bVizZg26deuGkSNHonPnzggPD0dwcDDWrVuHESNG1EacREREREajdwXo+vXraNCgAYCK8T7Xr18HADzxxBPIyMgwbnRERERkWpWzwAxdzIzeFaAGDRrg/PnzeOyxx9C4cWNs3LgR7du3x7Zt2zQPRyUyJcfTSii2/QGH83dgd6McV94Ixu12Cq1j7H8vRr31+XD6pQhQC5TVd8SVicFQeTmYKGqqkZ+KIX1+CzhbCumaGupET+AJ57/331FDWlkA7L8DFKoBP1uIIXKgv6vpYiajcXYoxX96H0HXZudRz/UOfrvkhf/b1gmnL/qYOjSLwjtB/2XkyJE4ceIEAGDKlClYunQpHB0dMWHCBCQkJBg9QEPFxsY+9OaM3bp1w/jx4zXrISEhWvc+kiQJW7durZX4Zs2ahVatWtVK29ZKKlajNNgJ10bWv+9+u8sl8J+ZjbIAR+TPCMPv7zbEzSE+EPZ6/+9ApnZHAGEOEOPuPwFDWn4TOFIM8aYHRLIfxFA5pCU3gAN36jZOqhVvDU1H+4iLmLXxSYxY9BwOnw3EBy9th7eb0tSh0SNA7wrQhAkTNP/u2bMnfv31Vxw7dgzh4eFo2bKlXm3Fxsbik08+qQjEzg6BgYF49tlnMXv2bDg6OuobWo1t3rwZ9vb2Ovfn5+drZrjl5OQgNDQUx48f1ztxkSQJW7Zs0UrI4uPjMXbs2JqETTrcae2GO611346h3ueXcaeVHDdG+Gu2lfvJ6iI0MrYOThAdnP5auVZ1/6kSiN7OQKu/fp487QpsV0L6tRSio1PV4+mRIbMrR/fm5zBpTTQyz1c8h3LV7nbo3PgChvzjF6z4X3sTR2hBeB+g+wsODkZwcHCNz4+OjkZycjLKyspw7NgxxMTEQJIkvPvuu4aGVm0eHh4P3O/n51dr13Z1dYWrK8vxdUYt4Hz8Fgr6e8P3nXOQ5dxBmbcDCgb5VOkmIwvQTAbp4B2IaBfAyxbILAEulkO8xoT3UWdro4adrUBJua3W9pJyO0SG5JsoKnqUVKvmv2TJkmov+pLJZPDz80NQUBAGDRqEnj17YteuXQAAtVqNpKQkhIaGwsnJCZGRkdi0aZPmXJVKhVGjRmn2N2rUCIsXL77vdRITE+Ht7Q03Nze88sorWjdwvLcL7F53d4GFhoYCAFq3bg1JktCtWzcAwJEjR9CrVy94eXlBoVCga9eu+PHHHzVthISEAAAGDx4MSZI06/d2ganVasyePRuBgYGQyWRo1aoVUlNTNftzcnIgSRI2b96M7t27w9nZGZGRkTh48OAD32eqYFtYDptiNRRfX8WdSDkuv9UAt9sr4PN/F+D4C8vmlkbE1QMes4fNsHxIfS5CevOPiu6ylnVXYabacbvUAT9d8MWLPY7BS14EG0mN6Fa/ofljV+Alv23q8CyKhL/HAdV4MfWLuI9qVYAWLlxYrcYkScK4ceNqHMzJkydx4MABTUUpKSkJn376KT788ENEREQgIyMDL7zwAry9vdG1a1eo1WoEBgbiiy++gKenJw4cOICXX34Z/v7+eO655zTtpqWlwdHREXv27EFOTg5GjhwJT09PzJ07V+8Yf/jhB7Rv3x67d+9Gs2bN4OBQMWj21q1biImJwfvvvw8hBBYsWIB+/frh7NmzkMvlOHLkCHx8fJCcnIzo6GjY2tret/3FixdjwYIFWLFiBVq3bo3Vq1djwIABOHXqFCIiIjTHTZ06FfPnz0dERASmTp2K4cOHIysrS/OA2nuVlJSgpKREs15YWKj3a7cI6or/3H5cgcKnvAEApSFOkP1WBPnuayhuymqcRdl6CzhdCvUcL8DXFvi5BNKSGxCetsDjTIIedbM+fxLTntmDHVPXolwl4cwlL/zvRDga1//D1KHRI6BaCdD58+drLYDt27fD1dUV5eXlKCkpgY2NDT744AOUlJTgnXfewe7duxEVFQWgYgbavn37sGLFCnTt2hX29vZITEzUtBUaGoqDBw9i48aNWgmQg4MDVq9eDWdnZzRr1gyzZ89GQkIC5syZAxsb/Qa+entX/NL09PTU6hp78skntY776KOP4O7ujvT0dDz99NOa89zd3R/YpTZ//nxMnjwZw4YNAwC8++67+P7777Fo0SIsXbpUc1x8fDyeeuopABXVrWbNmiErKwuNGze+b7tJSUla75W1UrnZQtgCZYHaXSBlAY5wPFNkoqioVpSoIX1cAJHoBfzjr/E+YQ5AVhmkL25BMAF65P1+XYFXPxoIR/syuDiW4totF7w9fBcuXecjmYzKQh+GavJpL927d0dmZiYOHz6MmJgYjBw5EkOHDkVWVhZu376NXr16acbJuLq6Ys2aNcjOztacv3TpUjz++OPw9vaGq6srPvroI+Tm5mpdIzIyEs7Of0+NjYqKglKpRF5entFex5UrVzB69GhERERAoVDAzc0NSqWySiwPUlhYiEuXLqFTp05a2zt16oTTp09rbbt7wLm/f8Vg3qtXr+ps+80330RBQYFmMeZrf6TY2aCkgTPsL5Vobba/XIJyToG3LOWAVI6qtXcbAGozHJFJNVZcZo9rt1wgdyrBPxrmIeOXEFOHZFl4J+ja4eLigvDwcADA6tWrERkZiY8//hjNmzcHAOzYsQP162tPZ5bJKv5637BhA+Lj47FgwQJERUVBLpfjvffew+HDh+v2RQCIiYnBtWvXsHjxYgQHB0MmkyEqKqrKw2KN5e5Za5JU8RNerVbrPF4mk2neN0snFatgf/nv993uaikccu5A5WoLlZcDCvp7w2dxLoqbXMOdZq5wyrwF52OFyJ8RZsKoqUbuqIHfy/9ev6wCskoBuQ3gawcRKYP00U0ImQT42gEnSoBdtyFedTdZyGQ8HSLyIEkCF/5wR5BnAcb2O4QLf7hj29FGpg6NHgEmT4DuZmNjg7feegsTJ07Eb7/9BplMhtzcXHTt2vW+x+/fvx8dO3bEa6+9ptl2d3Wo0okTJ3Dnzh04OVWUwQ8dOgRXV1cEBQXpHWPlmB+VSlUllmXLlqFfv34AgLy8PPz5559ax9jb21c5725ubm4ICAjA/v37tV7z/v370b49p3RWlyz7DvznnNOse66tmBFyq0s9/PlaEG63V+DPl+rD/aur8Ei5hLIAGa5ODEZJYxdThUw1daYUNm/8Pd7DZvlNAIDo7Qwx2RNimiekVTchvXMduKUGfG0hXlQA/flZWwJXxxK8Fv0DfBRKFN52xPcnQ7H82/ZQqe8/xpJqiNPg68azzz6LhIQErFixAvHx8ZgwYQLUajWeeOIJFBQUYP/+/XBzc0NMTAwiIiKwZs0afPvttwgNDcXatWtx5MgRzUytSqWlpRg1ahSmTZuGnJwczJw5E3FxcXqP/wEAHx8fODk5ITU1FYGBgXB0dIRCoUBERATWrl2Ltm3borCwEAkJCZqEq1JISAjS0tLQqVMnyGQyzb2F7paQkICZM2ciLCwMrVq1QnJyMjIzM7Fu3Tq9Y7VWxc1ccX7Dg+9JpezuAWX3B9/+gB4BrRyhTnvAHzIethCTPOsuHqpTaT+HI+3ncFOHYfF4J+g6Ymdnh7i4OMybNw9vvvkmpk+fjqSkJDRp0gTR0dHYsWOHJsH5z3/+gyFDhuD5559Hhw4dcO3aNa1qUKUePXogIiICXbp0wfPPP48BAwZg1qxZNY5vyZIlWLFiBQICAjBw4EAAwMcff4wbN26gTZs2+Ne//oVx48bBx0f7duwLFizArl27EBQUhNatW9+3/XHjxmHixIl444030KJFC6SmpuLrr7/WmgFGREREhpGEEHrnZXv37sWKFSuQnZ2NTZs2oX79+li7di1CQ0PxxBNP1EacZGSFhYVQKBQITX4LNs6cDWPpgr1vmDoEqkOFnwSaOgSqZarSYhz/bCoKCgrg5lY7s94qf0+EvD0XNgY+nUFdXIycabUbr770rgB9+eWX6NOnD5ycnHD8+HHNvWUKCgrwzjvvGD1AIiIiMiELnQWmdwL09ttv48MPP8TKlSu1ZiJ16tRJ687HREREROZK70HQZ86cQZcuXapsVygUuHnzpjFiIiIiIjPBQdB/8fPzQ1ZWVpXt+/btQ4MGDYwSFBEREZmJyjtBG7qYGb0ToNGjR+P111/H4cOHIUkSLl26hHXr1iE+Ph6vvvpqbcRIREREpmKhY4D07gKbMmUK1Go1evTogdu3b6NLly6QyWSIj4/H2LFjayNGIiIiIqPSOwGSJAlTp05FQkICsrKyoFQq0bRpU7i68inaRERElsZSxwDV+E7QDg4OaNq0qTFjISIiInPDR2FU6N69u+bhm/fz3XffGRQQERERUW3TOwFq1aqV1npZWRkyMzNx8uRJxMTEGCsuIiIiMgdG6AKziArQwoUL77t91qxZUCqVBgdEREREZsRCu8CM9jDUF154AatXrzZWc0RERES1psaDoO918OBBOBr4sDQiIiIyMxZaAdI7ARoyZIjWuhAC+fn5OHr0KKZPn260wIiIiMj0OA3+LwqFQmvdxsYGjRo1wuzZs9G7d2+jBUZERERUW/RKgFQqFUaOHIkWLVqgXr16tRUTERERUa3SaxC0ra0tevfuzae+ExERWQsLfRaY3rPAmjdvjnPnztVGLERERGRmKscAGbqYG70ToLfffhvx8fHYvn078vPzUVhYqLUQERERmbtqjwGaPXs23njjDfTr1w8AMGDAAK1HYgghIEkSVCqV8aMkIiIi0zHDCo6hqp0AJSYm4pVXXsH3339fm/EQERGRObH2+wAJURF9165day0YIiIiorqg1zT4Bz0FnoiIiCwPb4QIoGHDhg9Ngq5fv25QQERERGRGrL0LDKgYB3TvnaCJiIiIHjV6JUDDhg2Dj49PbcVCREREZsbqu8A4/oeIiMgKWWgXWLVvhFg5C4yIiIjoUVftCpBara7NOIiIiMgcWWgFSK8xQERERGRdrH4MEBEREVkhC60A6f0wVCIiIqJHHStAREREpJuFVoCYABEREZFOljoGiF1gREREZHVYASIiIiLd2AVGRERE1oZdYEREREQWghUgIiIi0o1dYERERGR1LDQBYhcYERERWR1WgIiIiEgn6a/F0DbMDRMgIiIi0s1Cu8CYABEREZFOnAZPREREZCGYABEREZFuwkiLHjIyMtC/f38EBARAkiRs3bpVOyQhMGPGDPj7+8PJyQk9e/bE2bNn9boGEyAiIiJ6sDpMfgCgqKgIkZGRWLp06X33z5s3D0uWLMGHH36Iw4cPw8XFBX369EFxcXG1r8ExQERERGRW+vbti759+953nxACixYtwrRp0zBw4EAAwJo1a+Dr64utW7di2LBh1boGK0BERESkU+UgaEMXACgsLNRaSkpK9I7n/PnzuHz5Mnr27KnZplAo0KFDBxw8eLDa7TABIiIiIt2MOAYoKCgICoVCsyQlJekdzuXLlwEAvr6+Wtt9fX01+6qDXWBERERUJ/Ly8uDm5qZZl8lkJouFFSAiIiLSyZhdYG5ublpLTRIgPz8/AMCVK1e0tl+5ckWzrzqYABEREZFuJpgG/yChoaHw8/NDWlqaZlthYSEOHz6MqKioarfDLjAiIiIyK0qlEllZWZr18+fPIzMzEx4eHnjssccwfvx4vP3224iIiEBoaCimT5+OgIAADBo0qNrXYAJk5YJHnoKdZG/qMKiWiY6Rpg6B6pDnL7+YOgSqZeWitM6uZYpHYRw9ehTdu3fXrE+cOBEAEBMTg5SUFEyaNAlFRUV4+eWXcfPmTTzxxBNITU2Fo6Njta/BBIiIiIh0M8HDULt16wYhdJ8kSRJmz56N2bNn1zgkJkBERESkm4U+DZ6DoImIiMjqsAJEREREOpliDFBdYAJEREREurELjIiIiMgysAJEREREOklCQHrAjKzqtmFumAARERGRbuwCIyIiIrIMrAARERGRTpwFRkRERNaHXWBEREREloEVICIiItKJXWBERERkfSy0C4wJEBEREelkqRUgjgEiIiIiq8MKEBEREenGLjAiIiKyRubYhWUodoERERGR1WEFiIiIiHQTomIxtA0zwwSIiIiIdOIsMCIiIiILwQoQERER6cZZYERERGRtJHXFYmgb5oZdYERERGR1WAEiIiIi3dgFRkRERNbGUmeBMQEiIiIi3Sz0PkAcA0RERERWhxUgIiIi0oldYERERGR9LHQQNLvAiIiIyOqwAkREREQ6sQuMiIiIrA9ngRERERFZBlaAiIiISCd2gREREZH14SwwIiIiIsvAChARERHpxC4wIiIisj5qUbEY2oaZYQJEREREunEMEBEREZFlYAWIiIiIdJJghDFARonEuJgAERERkW68EzQRERGRZWAFiIiIiHTiNHgiIiKyPpwFRkRERGQZWAEiIiIinSQhIBk4iNnQ82sDEyAiIiLSTf3XYmgbZoZdYERERGR1WAEiIiIindgFRkRERNbHQmeBMQEiIiIi3XgnaCIiIiLLwAoQERER6cQ7QZNZSElJwfjx43Hz5k1Th/LIeD7uCjr1K0BQeAlKi23wy1FnfDzXHxezHU0dGtUCT4/beOmFY2jX+nfIHFS4dFmO+cs64my2l6lDIyPq9/wlPDUsH771iwEAF7Kc8dnyYBzd62HiyCwQu8AIAGJjYyFJEiRJgr29PXx9fdGrVy+sXr0aarVxb3QQEhKCRYsWGbVNa9QyqgjbUrww/ukIvDmsAWztBN757BxkTipTh0ZG5upSgoVvf4PychtMndsToycMwEdr2kKplJk6NDKyP6/IkLwwFOOebYPXn22NE4fdMf2DU3gsvMjUodEjghWgGoiOjkZycjJUKhWuXLmC1NRUvP7669i0aRO+/vpr2NnxbTUnU0c00FpfMP4xbDx5ChEt7+DkYVcTRUW14blBJ/HHNRcsWNZJs+3yVbkJI6La8sMeT631NYtD8dSwfDRuWYjcLBcTRWWZJHXFYmgb5oYVoBqQyWTw8/ND/fr10aZNG7z11lv46quv8M033yAlJQUAcPPmTbz00kvw9vaGm5sbnnzySZw4cULTRnZ2NgYOHAhfX1+4urqiXbt22L17t2Z/t27dcOHCBUyYMEFTcbrbt99+iyZNmsDV1RXR0dHIz8+vk9duCVzcKio/t27amjgSMraothdxNtsT095Ix8aPN2LZe9vQt+dvpg6LapmNjUCXvlfh6KTC6RNupg7H8lR2gRm6mBkmQEby5JNPIjIyEps3bwYAPPvss7h69Sq++eYbHDt2DG3atEGPHj1w/fp1AIBSqUS/fv2QlpaG48ePIzo6Gv3790dubi4AYPPmzQgMDMTs2bORn5+vleDcvn0b8+fPx9q1a5GRkYHc3FzEx8c/ML6SkhIUFhZqLdZIkgReSfwdJ39wxoUzTqYOh4zM3/cWnu59Br/ny/Hm2z2w/dtGeG3kEfTqmm3q0KgWhEQU4cuj+/BV5l7EzTyLOeOaIS+b1R+qHiZARtS4cWPk5ORg3759+OGHH/DFF1+gbdu2iIiIwPz58+Hu7o5NmzYBACIjI/Gf//wHzZs3R0REBObMmYOwsDB8/fXXAAAPDw/Y2tpCLpfDz88Pfn5+muuUlZXhww8/RNu2bdGmTRvExcUhLS3tgbElJSVBoVBolqCgoNp7I8xY3Du/I7hxMZJeDTZ1KFQLJAk4e94TyevbIPu8J3bubohv0iLwVO8zpg6NasHFHCfEDXkcE4a1xs7PA/DGO2cQFMYxQEYnjLSYGSZARiSEgCRJOHHiBJRKJTw9PeHq6qpZzp8/j+zsir9ElUol4uPj0aRJE7i7u8PV1RWnT5/WVIAexNnZGWFhYZp1f39/XL169YHnvPnmmygoKNAseXl5hr3YR9CYuRfRoVchJj0Thj/zHUwdDtWC6zedkJun0NqWe1EBHy/+UrRE5WU2yM91QtYvcqQsDMW5My4Y+K/fTR2Wxal8FIahi7nhaF0jOn36NEJDQ6FUKuHv7489e/ZUOcbd3R0AEB8fj127dmH+/PkIDw+Hk5MTnnnmGZSWlj70Ovb29lrrkiRBPOTLJZPJIJNZ60wYgTFzf0fH6AIkPBOOK3nW+j5YvlO/eiOwvnb3bmBAIa78ycHu1sBGErC3N79ftGSemAAZyXfffYeff/4ZEyZMQGBgIC5fvgw7OzuEhITc9/j9+/cjNjYWgwcPBlBREcrJydE6xsHBASoVp2obKu6d39F98A3MGhmKO0ob1PMuAwAU3bJFaTGLoJZk8/amWDT3Gwwb8jMyDgSjUfif6NfzLBat+IepQyMji51wHkcz6uFqviOcXVTo9vRVtGhfgOmjHzN1aJbHQu8DxASoBkpKSnD58mWtafBJSUl4+umn8e9//xs2NjaIiorCoEGDMG/ePDRs2BCXLl3Cjh07MHjwYM24oM2bN6N///6QJAnTp0+vch+hkJAQZGRkYNiwYZDJZPDy4o3caqJ/7DUAwPzN2gNh548Pwq6NvGmaJfkt2wuJ73XHi//8ES88cwKXr8qxPKUtvtvb4OEn0yNF4VGKN/57Bh7epSi6ZYfzv7lg+ugWOH6wnqlDszwCgKHT2M0v/2ECVBOpqanw9/eHnZ0d6tWrh8jISCxZsgQxMTGwsamoKOzcuRNTp07FyJEj8ccff8DPzw9dunSBr68vAOD//u//8OKLL6Jjx47w8vLC5MmTq8zMmj17Nv7zn/8gLCwMJSUlD+3movvrExBp6hCoDh0+FojDxwJNHQbVssXTG5k6BKthjDE85jgGSBL8rWqVCgsLoVAo0A0DYSfZP/wEeqSJjkwCrYndLzmmDoFqWbkoRdrNtSgoKICbW+3c+6jy98STrafAztawRweVq4rx3fH/1mq8+mIFiIiIiHQTMMIYIKNEYlRMgIiIiEg3Cx0EzSkwREREZDZmzZqleQRU5dK4cWOjX4cVICIiItJNDUB66FEPb0MPzZo103o+Zm08ZJwJEBEREelkillgdnZ2Wo+Aqg3sAiMiIiKzcvbsWQQEBKBBgwYYMWJEtR4TpS9WgIiIiEg3Iw6Cvvd+d/d7TFOHDh2QkpKCRo0aIT8/H4mJiejcuTNOnjwJuVxuWBx3YQWIiIiIdKtMgAxdAAQFBUGhUGiWpKSkKpfr27cvnn32WbRs2RJ9+vTBzp07cfPmTWzcuNGoL4sVICIiIqoTeXl5WjdCrM5Dut3d3dGwYUNkZWUZNRZWgIiIiEg3I1aA3NzctJbqJEBKpRLZ2dnw9/c36stiAkRERES6qY20VFN8fDzS09ORk5ODAwcOYPDgwbC1tcXw4cON9pIAdoERERHRA9T1NPiLFy9i+PDhuHbtGry9vfHEE0/g0KFD8Pb2NiiGezEBIiIiIrOxYcOGOrkOEyAiIiLSzUKfBcYEiIiIiHRTC0AyMIFRm18CxEHQREREZHVYASIiIiLd2AVGRERE1scICRDMLwFiFxgRERFZHVaAiIiISDd2gREREZHVUQsY3IXFWWBEREREpscKEBEREekm1BWLoW2YGSZAREREpBvHABEREZHV4RggIiIiIsvAChARERHpxi4wIiIisjoCRkiAjBKJUbELjIiIiKwOK0BERESkG7vAiIiIyOqo1QAMvI+P2vzuA8QuMCIiIrI6rAARERGRbuwCIyIiIqtjoQkQu8CIiIjI6rACRERERLpZ6KMwmAARERGRTkKoIQx8mruh59cGJkBERESkmxCGV3A4BoiIiIjI9FgBIiIiIt2EEcYAmWEFiAkQERER6aZWA5KBY3jMcAwQu8CIiIjI6rACRERERLqxC4yIiIisjVCrIQzsAjPHafDsAiMiIiKrwwoQERER6cYuMCIiIrI6agFIlpcAsQuMiIiIrA4rQERERKSbEAAMvQ+Q+VWAmAARERGRTkItIAzsAhNMgIiIiOiRItQwvALEafBEREREJscKEBEREenELjAiIiKyPhbaBcYEyEpVZuPlKDP4/lZk/kR5salDoLokSk0dAdWy8r8+47qorBjj90Q5yowTjBExAbJSt27dAgDsw04TR0J14vBXpo6AiGrBrVu3oFAoaqVtBwcH+Pn5Yd9l4/ye8PPzg4ODg1HaMgZJmGPHHNU6tVqNS5cuQS6XQ5IkU4dTJwoLCxEUFIS8vDy4ubmZOhyqRfysrYs1ft5CCNy6dQsBAQGwsam9+UzFxcUoLTVORdHBwQGOjo5GacsYWAGyUjY2NggMDDR1GCbh5uZmNT8krR0/a+tibZ93bVV+7ubo6GhWSYsxcRo8ERERWR0mQERERGR1mACR1ZDJZJg5cyZkMpmpQ6Faxs/auvDzpprgIGgiIiKyOqwAERERkdVhAkRERERWhwkQERERWR0mQPTICQkJwaJFi0wdBtWi2NhYDBo06IHHdOvWDePHj9es3/u9kCQJW7durZX4Zs2ahVatWtVK21Q3UlJS4O7ubuowyISYAJFRxcbGQpIkzeLp6Yno6Gj89NNPdRZDUlIS2rVrB7lcDh8fHwwaNAhnzpzROkZXEsVfbA9392dsb2+P0NBQTJo0CcXFdfu8sc2bN2POnDk69+fn56Nv374AgJycHEiShMzMTL2vc79EKj4+HmlpaXq3RX+793vk6+uLXr16YfXq1VCrjfvgTP7RRPfDBIiMLjo6Gvn5+cjPz0daWhrs7Ozw9NNP19n109PTMWbMGBw6dAi7du1CWVkZevfujaKiojqLwdJVfsbnzp3DwoULsWLFCsycObNOY/Dw8IBcLte538/Pr9amRbu6usLT07NW2rYmld+jnJwcfPPNN+jevTtef/11PP300ygvLzd1eGThmACR0clkMvj5+cHPzw+tWrXClClTkJeXhz/++AMAMHnyZDRs2BDOzs5o0KABpk+fjrIy7ScFb9u2De3atYOjoyO8vLwwePBgnddbtWoV3N3dNX+Rp6amIjY2Fs2aNUNkZCRSUlKQm5uLY8eO6f1a1Go1Zs+ejcDAQMhkMrRq1Qqpqama/ZWVhY0bN6Jz585wcnJCu3bt8Ntvv+HIkSNo27YtXF1d0bdvX83rvzvuJk2awNHREY0bN8ayZcv0js9UKj/joKAgDBo0CD179sSuXbsAVLxnSUlJCA0NhZOTEyIjI7Fp0ybNuSqVCqNGjdLsb9SoERYvXnzf6yQmJsLb2xtubm545ZVXtJ5JdG8X2L3urtyEhoYCAFq3bg1JktCtWzcAwJEjR9CrVy94eXlBoVCga9eu+PHHHzVthISEAAAGDx4MSZI06/dWCqv7Pdm8eTO6d+8OZ2dnREZG4uDBgw98ny1d5feofv36aNOmDd566y189dVX+Oabb5CSkgIAuHnzJl566SXN9+DJJ5/EiRMnNG1kZ2dj4MCB8PX1haurK9q1a4fdu3dr9nfr1g0XLlzAhAkTNBWnu3377bdo0qQJXF1dNQkZWQcmQFSrlEolPv30U4SHh2v+YpbL5UhJScEvv/yCxYsXY+XKlVi4cKHmnB07dmDw4MHo168fjh8/jrS0NLRv3/6+7c+bNw9TpkzB//73P/To0eO+xxQUFACoqBjoa/HixViwYAHmz5+Pn376CX369MGAAQNw9uxZreNmzpyJadOm4ccff4SdnR3++c9/YtKkSVi8eDH27t2LrKwszJgxQ3P8unXrMGPGDMydOxenT5/GO++8g+nTp+OTTz7RO0ZTO3nyJA4cOKB5ynNSUhLWrFmDDz/8EKdOncKECRPwwgsvID09HUBFshAYGIgvvvgCv/zyC2bMmIG33noLGzdu1Go3LS0Np0+fxp49e/DZZ59h8+bNSExMrFGMP/zwAwBg9+7dyM/Px+bNmwFUPEk7JiYG+/btw6FDhxAREYF+/frh1q1bACoSJABITk5Gfn6+Zv1e1f2eTJ06FfHx8cjMzETDhg0xfPhwVjru8eSTTyIyMlLzGT377LO4evUqvvnmGxw7dgxt2rRBjx49cP36dQAVP2P69euHtLQ0HD9+HNHR0ejfvz9yc3MBVHSVBgYGYvbs2ZrKdKXbt29j/vz5WLt2LTIyMpCbm4v4+Pi6f9FkGoLIiGJiYoStra1wcXERLi4uAoDw9/cXx44d03nOe++9Jx5//HHNelRUlBgxYoTO44ODg8XChQvFpEmThL+/vzh58qTOY1UqlXjqqadEp06dqrTh4OCgibNysbe3F5GRkZrjAgICxNy5c7XObdeunXjttdeEEEKcP39eABCrVq3S7P/ss88EAJGWlqbZlpSUJBo1aqRZDwsLE+vXr9dqd86cOSIqKkrnazEXd3/GMplMABA2NjZi06ZNori4WDg7O4sDBw5onTNq1CgxfPhwnW2OGTNGDB06VOsaHh4eoqioSLNt+fLlwtXVVahUKiGEEF27dhWvv/66Zn/l96ISALFlyxYhxN+f0/Hjxx/42lQqlZDL5WLbtm33bafSzJkzDf6enDp1SgAQp0+ffmBMliomJkYMHDjwvvuef/550aRJE7F3717h5uYmiouLtfaHhYWJFStW6Gy7WbNm4v3339es3/vdEEKI5ORkAUBkZWVpti1dulT4+vrq/2LokcSnwZPRde/eHcuXLwcA3LhxA8uWLUPfvn3xww8/IDg4GJ9//jmWLFmC7OxsKJVKlJeXaz3BOTMzE6NHj37gNRYsWICioiIcPXoUDRo00HncmDFjcPLkSezbt6/KvoSEBMTGxmptW7JkCTIyMgAAhYWFuHTpEjp16qR1TKdOnbRK8ADQsmVLzb99fX0BAC1atNDadvXqVQBAUVERsrOzMWrUKK3XWV5eXidPdzaGys+4qKgICxcuhJ2dHYYOHYpTp07h9u3b6NWrl9bxpaWlaN26tWZ96dKlWL16NXJzc3Hnzh2UlpZWGXweGRkJZ2dnzXpUVBSUSiXy8vIQHBxslNdx5coVTJs2DXv27MHVq1ehUqlw+/ZtTfWgOmr6PfH39wcAXL16FY0bNzbgVVgeIQQkScKJEyegVCqrjLe6c+cOsrOzAVRUgGbNmoUdO3YgPz8f5eXluHPnTrU+Q2dnZ4SFhWnW/f39Nf+fkuVjAkRG5+LigvDwcM36qlWroFAosHLlSjz11FMYMWIEEhMT0adPHygUCmzYsAELFizQHO/k5PTQa3Tu3Bk7duzAxo0bMWXKlPseExcXh+3btyMjIwOBgYFV9nt5eWnFCdSsmwwA7O3tNf+uHGNw77bKmS1KpRIAsHLlSnTo0EGrHVtb2xpdv67d/RmvXr0akZGR+Pjjj9G8eXMAFd2Y9evX1zqnckDyhg0bEB8fjwULFiAqKgpyuRzvvfceDh8+XLcvAkBMTAyuXbuGxYsXIzg4GDKZDFFRUVpjjYzpft8TY894sgSnT59GaGgolEol/P39sWfPnirHVE5hj4+Px65duzB//nyEh4fDyckJzzzzTLU+w7s/D6DiMxF8OpTVYAJEtU6SJNjY2ODOnTs4cOAAgoODMXXqVM3+CxcuaB3fsmVLpKWlYeTIkTrbbN++PeLi4hAdHQ07OzutfnshBMaOHYstW7Zgz549mgGw+nJzc0NAQAD279+Prl27arbv379f55ik6vD19UVAQADOnTuHESNG1Lgdc2FjY4O33noLEydOxG+//QaZTIbc3Fyt9+xu+/fvR8eOHfHaa69ptlX+NX+3EydO4M6dO5qE+NChQ3B1dUVQUJDeMVaOT1KpVFViWbZsGfr16wcAyMvLw59//ql1jL29fZXz7lZb3xNr9d133+Hnn3/GhAkTEBgYiMuXL8POzk4zAP1e+/fvR2xsrGaihFKpRE5OjtYxDg4OD/wMyToxASKjKykpweXLlwFUdIF98MEHUCqV6N+/PwoLC5Gbm4sNGzagXbt22LFjB7Zs2aJ1/syZM9GjRw+EhYVh2LBhKC8vx86dOzF58mSt4zp27IidO3eib9++sLOz08wIGjNmDNavX4+vvvoKcrlcE4tCoahWdeluCQkJmDlzJsLCwtCqVSskJycjMzMT69atq+G7UyExMRHjxo2DQqFAdHQ0SkpKcPToUdy4cQMTJ040qG1TePbZZ5GQkIAVK1YgPj4eEyZMgFqtxhNPPIGCggLs378fbm5uiImJQUREBNasWYNvv/0WoaGhWLt2LY4cOVIlUS0tLcWoUaMwbdo05OTkYObMmYiLi4ONjf5zN3x8fODk5ITU1FQEBgbC0dERCoUCERERWLt2Ldq2bYvCwkIkJCRU+Y6EhIQgLS0NnTp1gkwmQ7169aq0X1vfE0tX+bNCpVLhypUrSE1NRVJSEp5++mn8+9//ho2NDaKiojBo0CDMmzcPDRs2xKVLlzQTJdq2bYuIiAhs3rwZ/fv3hyRJmD59epWqWkhICDIyMjBs2DDIZDJ4eXmZ6BWTWTHxGCSyMDExMQKAZpHL5aJdu3Zi06ZNmmMSEhKEp6encHV1Fc8//7xYuHChUCgUWu18+eWXolWrVsLBwUF4eXmJIUOGaPbdO6AxPT1duLi4iCVLlgghhNb1716Sk5N1tlHp3sGtKpVKzJo1S9SvX18zQPqbb77R7L/f4Nrvv/9eABA3btzQbEtOTq7yGtetW6d5jfXq1RNdunQRmzdv1v3mmgldg1eTkpKEt7e3UCqVYtGiRaJRo0bC3t5eeHt7iz59+oj09HQhhBDFxcUiNjZWKBQK4e7uLl599VUxZcoUrfe98hozZszQfFdGjx6tNRhWn0HQQgixcuVKERQUJGxsbETXrl2FEEL8+OOPom3btsLR0VFERESIL774oko7X3/9tQgPDxd2dnYiODhYCGGc78mNGzcEAPH9998/7C23SHf/rLCzsxPe3t6iZ8+eYvXq1ZqB7kIIUVhYKMaOHSsCAgKEvb29CAoKEiNGjBC5ublCiIr3tnv37sLJyUkEBQWJDz74oMp34+DBg6Jly5aaQftC3P//yS1btgj+WrQekhDs8CQiIiLrwvsAERERkdVhAkRERERWhwkQERERWR0mQERERGR1mAARERGR1WECRERERFaHCRARERFZHSZARGQysbGxGDRokGa9W7dumjt616U9e/ZAkiTcvHlT5zGSJGHr1q3VbnPWrFlVHvCqr5ycHEiShMzMTIPaIaKqmAARkZbY2FhIkgRJkuDg4IDw8HDMnj0b5eXltX7tzZs3Y86cOdU6tjpJCxGRLnwWGBFVER0djeTkZJSUlGDnzp0YM2YM7O3t8eabb1Y5trS0VPOwUUN5eHgYpR0ioodhBYiIqpDJZPDz80NwcDBeffVV9OzZE19//TWAv7ut5s6di4CAADRq1AhAxZPUn3vuObi7u8PDwwMDBw7Ueiq3SqXCxIkT4e7uDk9PT0yaNAn3Ponn3i6wkpISTJ48GUFBQZDJZAgPD8fHH3+MnJwcdO/eHQBQr149SJKE2NhYAIBarUZSUhJCQ0Ph5OSEyMhIbNq0Ses6O3fuRMOGDeHk5ITu3btXeXp4dUyePBkNGzaEs7MzGjRogOnTp6OsrKzKcStWrEBQUBCcnZ3x3HPPoaCgQGv/qlWr0KRJEzg6OqJx48ZYtmyZ3rEQkf6YABHRQzk5OaG0tFSznpaWhjNnzmDXrl3Yvn07ysrK0KdPH8jlcuzduxf79++Hq6sroqOjNectWLAAKSkpWL16Nfbt24fr169jy5YtD7zuv//9b3z22WdYsmQJTp8+jRUrVsDV1RVBQUH48ssvAQBnzpxBfn4+Fi9eDABISkrCmjVr8OGHH+LUqVOYMGECXnjhBaSnpwOoSNSGDBmC/v37IzMzEy+99BKmTJmi93sil8uRkpKCX375BYsXL8bKlSuxcOFCrWOysrKwceNGbNu2DampqTh+/Dhee+01zf5169ZhxowZmDt3Lk6fPo133nkH06dPxyeffKJ3PESkJxM/jJWIzMzdT3tXq9Vi165dQiaTifj4eM1+X19fUVJSojln7dq1olGjRkKtVmu2lZSUCCcnJ/Htt98KIYTw9/cX8+bN0+wvKysTgYGBWk+Wv/sp3mfOnBEAxK5du+4b5/fffy8AiBs3bmi2FRcXC2dnZ3HgwAGtY0eNGiWGDx8uhBDizTffFE2bNtXaP3ny5Cpt3Qv3PF3+Xu+99554/PHHNeszZ84Utra24uLFi5pt33zzjbCxsRH5+flCCCHCwsLE+vXrtdqZM2eOiIqKEkLc/ynyRGQcHANERFVs374drq6uKCsrg1qtxj//+U/MmjVLs79FixZa435OnDiBrKwsyOVyrXaKi4uRnZ2NgoIC5Ofno0OHDpp9dnZ2aNu2bZVusEqZmZmwtbVF165dqx13VlYWbt++jV69emltLy0tRevWrQEAp0+f1ooDAKKioqp9jUqff/45lixZguzsbCiVSpSXl8PNzU3rmMceewz169fXuo5arcaZM2cgl8uRnZ2NUaNGYfTo0ZpjysvLoVAo9I6HiPTDBIiIqujevTuWL18OBwcHBAQEwM5O+0eFi4uL1rpSqcTjjz+OdevWVWnL29u7RjE4OTnpfY5SqQQA7NixQyvxACrGNRnLwYMHMWLECCQmJqJPnz5QKBTYsGEDFixYoHesK1eurJKQ2draGi1WIro/JkBEVIWLiwvCw8OrfXybNm3w+eefw8fHp0oVpJK/vz8OHz6MLl26AKiodBw7dgxt2rS57/EtWrSAWq1Geno6evbsWWV/ZQVKpVJptjVt2hQymQy5ubk6K0dNmjTRDOiudOjQoYe/yLscOHAAwcHBmDp1qmbbhQsXqhyXm5uLS5cuISAgQHMdGxsbNGrUCL6+vggICMC5c+cwYsQIva5PRIbjIGgiMtiIESPg5eWFgQMHYu/evTh//jz27NmDcePG4eLFiwCA119/Hf/973+xdetW/Prrr3jttdceeA+fkJAQxMTE4MUXX8TWrVs1bW7cuBEAEBwcDEmSsH37dvzxxx9QKpWQy+WIj4/HhAkT8MknnyA7Oxs//vgj3n//fc3A4ldeeQVnz55FQkICzpw5g/Xr1yMlJUWv1xsREYHc3Fxs2LAB2dnZWLJkyX0HdDs6OiImJgYnTpzA3r17MW7cODz33HPw8/MDACQmJiIpKQlLlizBb7/9hp9//hnJycn4v//7P73iISL9MQEiIoM5OzsjIyMDjz32GIYMGYImTZpg1KhRKC4u1lSE3njjDfzrX/9CTEwMoqKiIJfLMXjw4Ae2u3z5cjzzzDN47bXX0LhxY4wePRpFRUUAgPr16yMxMRFTpkyBr68v4uLiAABz5szB9OnTkZSUhCZNmiA6Oho7duxAaGgogIpxOV9++SW2bt2KyMhIfPjhh3jnnXf0er0DBgzAhAkTEBcXh1atWuHAgQOYPn16lePCw8MxZMgQ9OvXD71790bLli21prm/9NJLWLVqFZKTk9GiRQt07doVKSkpmliJqPZIQtcIRCIiIiILxQoQERERWR0mQERERGR1mAARERGR1WECRERERFaHCRARERFZHSZAREREZHWYABEREZHVYQJEREREVocJEBEREVkdJkBERERkdZgAERERkdVhAkRERERW5/8Buh9rAeNiSEwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(pd.DataFrame(test_y.cpu()).value_counts())\n",
    "\n",
    "model.eval()\n",
    "pred = model(data.edge_index, data.edge_type).argmax(dim=-1)\n",
    "matrix = confusion_matrix(data.test_y.cpu(), pred[data.test_idx].cpu())\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=[\"Back2Home\", \"Reabilitation\", \"Death\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurovasc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
