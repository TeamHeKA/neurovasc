{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient Outcome Prediction with RGCN+lit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mean, stdev\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support, roc_auc_score, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter, Linear\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.logging import log\n",
    "from torch_geometric.nn import RGCNConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data - SPHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patients = 10000 # the number of patients\n",
    "embed_dim = 32 # dimension of embedding vectors\n",
    "inverse_triples = False\n",
    "    \n",
    "entity = pd.read_csv(f'processed_data/sphn_entities_{num_patients}.tsv', sep='\\t', header=None)\n",
    "entity = entity.set_index(entity[1])\n",
    "entity = entity.to_dict()[0]\n",
    "\n",
    "patients = []\n",
    "for i in range(num_patients):\n",
    "    patient = f'<http://nvasc.org/synth_patient_{i}>'\n",
    "    patients.append(entity[patient])\n",
    "\n",
    "triples = pd.read_csv(f'processed_data/sphn_triples_{num_patients}.tsv', sep='\\t', header=None)\n",
    "if inverse_triples == True:\n",
    "    triples_inv = triples[[2, 1, 0]]\n",
    "    triples_inv.columns=[0,1,2]\n",
    "    triples_inv[1] += triples[1].max() + 1\n",
    "    triples = pd.concat((triples, triples_inv), axis=0)\n",
    "    triples = triples.reset_index()\n",
    "else:\n",
    "    triples_inv = triples[[2, 1, 0]]\n",
    "    triples_inv.columns=[0,1,2]\n",
    "    triples = triples_inv\n",
    "y = np.asarray(joblib.load(f'../../data/sphn_outcomes_{num_patients}.joblib'))\n",
    "num_x = torch.Tensor(np.load(f'processed_data/sphn_numeric_{num_patients}.npy'))\n",
    "\n",
    "edge_index = torch.vstack((torch.Tensor(triples[0]).long(),torch.Tensor(triples[2]).long()))\n",
    "edge_type = torch.Tensor(triples[1]).long()\n",
    "num_nodes = len(entity)\n",
    "\n",
    "data = Data(\n",
    "    edge_index=edge_index,\n",
    "    edge_type=edge_type,\n",
    "    num_nodes=num_nodes,      \n",
    ")\n",
    "embedding = Parameter(torch.empty(num_nodes, embed_dim))\n",
    "torch.nn.init.xavier_uniform_(embedding, gain=math.sqrt(2.0))\n",
    "data.x = embedding\n",
    "data.num_x = num_x.view(-1,1)\n",
    "data.num_relations = data.num_edge_types\n",
    "data.num_classes = 3\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'result/sphn/rgcnlit'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "def k_fold(X, y, folds):\n",
    "    skf = StratifiedKFold(folds, shuffle=True, random_state=42)\n",
    "    train_indices, val_indices, test_indices  = [], [], []\n",
    "    train_y, val_y, test_y = [], [], []\n",
    "    for (non_test_idx, test_idx) in skf.split(X, y):\n",
    "        test_indices.append(X[test_idx])\n",
    "        train_idx, val_idx, _, _ = train_test_split(non_test_idx, y[non_test_idx], test_size=1/9, random_state=42)\n",
    "        train_indices.append(X[train_idx])\n",
    "        val_indices.append(X[val_idx])\n",
    "        train_y.append(y[train_idx])\n",
    "        val_y.append(y[val_idx])\n",
    "        test_y.append(y[test_idx])\n",
    "    return train_indices, val_indices, test_indices, train_y, val_y, test_y\n",
    "\n",
    "metrics = []\n",
    "for fold, (train_idx, val_idx, test_idx, train_y, val_y, test_y) in enumerate(zip(*k_fold(np.asarray(patients), y, folds=10))):\n",
    "\n",
    "    data.train_idx = torch.Tensor(train_idx).long()\n",
    "    data.valid_idx = torch.Tensor(val_idx).long()\n",
    "    data.test_idx = torch.Tensor(test_idx).long()\n",
    "    \n",
    "    data.train_y = torch.Tensor(train_y).long()\n",
    "    data.valid_y = torch.Tensor(val_y).long()\n",
    "    data.test_y = torch.Tensor(test_y).long()\n",
    "\n",
    "    class Net(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.num_lin = Linear(1, embed_dim)\n",
    "            self.act_lin = torch.nn.PReLU(embed_dim)\n",
    "            self.conv1 = RGCNConv(embed_dim, 32, data.num_relations,\n",
    "                            num_bases=8)\n",
    "            self.act1 = torch.nn.PReLU(32)\n",
    "            self.conv2 = RGCNConv(32, 32, data.num_relations,\n",
    "                            num_bases=8)\n",
    "            self.act2 = torch.nn.PReLU(32)\n",
    "            self.conv3 = RGCNConv(32, data.num_classes, data.num_relations,\n",
    "                            num_bases=8)\n",
    "\n",
    "        def forward(self, edge_index, edge_type):\n",
    "            x = self.act_lin(self.num_lin(data.num_x))\n",
    "            x = x + data.x\n",
    "            x = self.act1(self.conv1(x, edge_index, edge_type))\n",
    "            x = F.dropout(x, p=0.2, training=self.training)\n",
    "            x = self.act2(self.conv2(x, edge_index, edge_type))\n",
    "            x = F.dropout(x, p=0.2, training=self.training)\n",
    "            x = self.conv3(x, edge_index, edge_type)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    model, data = Net().to(device), data.to(device)\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), \n",
    "        lr=1e-3, \n",
    "        weight_decay=5e-4,\n",
    "    )\n",
    "\n",
    "    def train():\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.edge_index, data.edge_type)\n",
    "        loss = F.nll_loss(out[data.train_idx], data.train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return float(loss)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test():\n",
    "        model.eval()\n",
    "        pred = model(data.edge_index, data.edge_type).argmax(dim=-1)\n",
    "        train_acc = float((pred[data.train_idx] == data.train_y).float().mean())\n",
    "        val_acc = float((pred[data.valid_idx] == data.valid_y).float().mean())\n",
    "        test_acc = float((pred[data.test_idx] == data.test_y).float().mean())\n",
    "        return train_acc, val_acc, test_acc\n",
    "\n",
    "    # Training\n",
    "    times = []\n",
    "    best_val_acc = final_test_acc = 0\n",
    "    for epoch in range(1, 2001):\n",
    "        start = time.time()\n",
    "        loss = train()\n",
    "        train_acc, val_acc, tmp_test_acc = test()\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            test_acc = tmp_test_acc\n",
    "            torch.save(model.state_dict(), f'result/sphn/rgcnlit/model_weights_{num_patients}.pth')\n",
    "        log(Epoch=epoch, Loss=loss, Train=train_acc, Val=val_acc, Test=test_acc)\n",
    "        times.append(time.time() - start)\n",
    "    \n",
    "    # Evaluation\n",
    "    model = Net().to(device)\n",
    "    model.load_state_dict(torch.load(f'result/sphn/rgcnlit/model_weights_{num_patients}.pth', weights_only=True))\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out = model(data.edge_index, data.edge_type)\n",
    "        y_pred = out.argmax(dim=-1)\n",
    "        y_prob = F.softmax(out, dim=-1)\n",
    "        accuracy = accuracy_score(data.test_y.cpu(), y_pred[data.test_idx].cpu())    \n",
    "        auc_score_class = roc_auc_score(data.test_y.cpu(), y_prob[data.test_idx].cpu(), average=None, multi_class='ovr')\n",
    "        auc_score_macro = roc_auc_score(data.test_y.cpu(), y_prob[data.test_idx].cpu(), average='macro', multi_class='ovr')\n",
    "        auc_score = roc_auc_score(data.test_y.cpu(), y_prob[data.test_idx].cpu(), average='weighted', multi_class='ovr')\n",
    "        precision_class, recall_class, fscore_class, _ = precision_recall_fscore_support(data.test_y.cpu(), y_pred[data.test_idx].cpu(), average=None)\n",
    "        precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(data.test_y.cpu(), y_pred[data.test_idx].cpu(), average='macro')\n",
    "        precision, recall, fscore, _ = precision_recall_fscore_support(data.test_y.cpu(), y_pred[data.test_idx].cpu(), average='weighted')\n",
    "\n",
    "    metric = pd.DataFrame({\n",
    "    'PRECISION': np.hstack((precision_class, precision_macro, precision)),\n",
    "    'RECALL': np.hstack((recall_class, recall_macro, recall)),\n",
    "    'F1SCORE': np.hstack((fscore_class, fscore_macro, fscore)),\n",
    "    'ACCURACY': np.hstack((np.zeros(4), accuracy)),\n",
    "    'AUC': np.hstack((auc_score_class, auc_score_macro, auc_score)),\n",
    "    }, index=['B2H', 'REHAB', 'DEATH', 'MACRO', 'WEIGHTED'])\n",
    "    metric.index.name = fold\n",
    "    metrics.append(metric)\n",
    "        \n",
    "panel = pd.concat(metrics)\n",
    "metrics_mean = panel.groupby(level=0).mean()\n",
    "metrics_mean.index.name = 'MEAN'\n",
    "metrics_std = panel.groupby(level=0).std()\n",
    "metrics_std.index.name = 'STD'\n",
    "metrics_mean.to_csv(f\"result/sphn/rgcnlit/metrics_{num_patients}.csv\", mode='a')\n",
    "metrics_std.to_csv(f\"result/sphn/rgcnlit/metrics_{num_patients}.csv\", mode='a')\n",
    "metrics_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurovasc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
