{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome Prediction with RGCN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data from \"processed_data\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.logging import log\n",
    "from torch_geometric.nn import RGCNConv\n",
    "from torch_geometric.utils import to_undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 221870], edge_type=[221870], train_idx=[700], train_y=[700], valid_idx=[100], valid_y=[100], test_idx=[200], test_y=[200], num_nodes=33563, x=[33563, 100], num_relations=10, num_classes=3)\n"
     ]
    }
   ],
   "source": [
    "num_patients = 1000\n",
    "inverse_triples=True\n",
    "embed_dim = 100\n",
    "\n",
    "entity = pd.read_csv(f'processed_data/sphn_entities_{num_patients}_noOutcome.tsv', sep='\\t', index_col=0, header=None)\n",
    "entity = entity.to_dict()[1]\n",
    "\n",
    "indices = []\n",
    "for i in range(num_patients):\n",
    "    idx = f'<http://nvasc.org/synth_patient_{i}>'\n",
    "    indices.append(entity[idx])\n",
    "\n",
    "events = pd.read_csv(f'processed_data/sphn_events_{num_patients}_noOutcome.tsv', sep='\\t', header=None)\n",
    "y = joblib.load(f'../Data Generation/outcomes_{num_patients}_0.joblib')\n",
    "\n",
    "non_test_X, test_X, non_test_y, test_y_ = train_test_split(indices, y, stratify=y, test_size=0.2)\n",
    "train_X, valid_X, train_y_, valid_y_ = train_test_split(non_test_X, non_test_y, stratify=non_test_y, test_size=1./8)\n",
    "\n",
    "edge_index = torch.vstack((torch.Tensor(events[0]).long(),torch.Tensor(events[2]).long()))\n",
    "edge_type = torch.Tensor(events[1]).long()\n",
    "train_idx = torch.Tensor(train_X).long()\n",
    "train_y = torch.Tensor(train_y_).long()\n",
    "valid_idx = torch.Tensor(valid_X).long()\n",
    "valid_y = torch.Tensor(valid_y_).long()\n",
    "test_idx = torch.Tensor(test_X).long()\n",
    "test_y = torch.Tensor(test_y_).long()\n",
    "num_nodes = len(entity)\n",
    "\n",
    "if inverse_triples == True:\n",
    "    edge_index = to_undirected(edge_index)\n",
    "    edge_type = torch.cat((edge_type, edge_type))\n",
    "\n",
    "data = Data(\n",
    "    edge_index=edge_index,\n",
    "    edge_type=edge_type,\n",
    "    train_idx=train_idx,\n",
    "    train_y=train_y,\n",
    "    valid_idx=valid_idx,\n",
    "    valid_y=valid_y,\n",
    "    test_idx=test_idx,\n",
    "    test_y=test_y,\n",
    "    num_nodes=num_nodes,\n",
    ")\n",
    "embedding = torch.nn.Parameter(torch.empty(num_nodes, embed_dim))\n",
    "torch.nn.init.xavier_uniform_(embedding, gain=math.sqrt(2.0))\n",
    "data.x = embedding\n",
    "data.num_relations = data.num_edge_types\n",
    "data.num_classes = 3\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = RGCNConv(embed_dim, 16, data.num_relations,\n",
    "                          num_bases=4)\n",
    "        self.conv2 = RGCNConv(16, data.num_classes, data.num_relations,\n",
    "                          num_bases=4)\n",
    "\n",
    "    def forward(self, edge_index, edge_type):\n",
    "        x = F.elu(self.conv1(data.x, edge_index, edge_type))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model, data = Net().to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.edge_index, data.edge_type)\n",
    "    loss = F.nll_loss(out[data.train_idx], data.train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    pred = model(data.edge_index, data.edge_type).argmax(dim=-1)\n",
    "    train_acc = float((pred[data.train_idx] == data.train_y).float().mean())\n",
    "    val_acc = float((pred[data.valid_idx] == data.valid_y).float().mean())\n",
    "    test_acc = float((pred[data.test_idx] == data.test_y).float().mean())\n",
    "    return train_acc, val_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 1.0992, Train: 0.4686, Val: 0.4900, Test: 0.4450\n",
      "Epoch: 002, Loss: 1.0673, Train: 0.4986, Val: 0.5100, Test: 0.4450\n",
      "Epoch: 003, Loss: 1.0311, Train: 0.5314, Val: 0.5000, Test: 0.4450\n",
      "Epoch: 004, Loss: 1.0067, Train: 0.5400, Val: 0.5000, Test: 0.4450\n",
      "Epoch: 005, Loss: 0.9780, Train: 0.5671, Val: 0.4600, Test: 0.4450\n",
      "Epoch: 006, Loss: 0.9646, Train: 0.5900, Val: 0.4800, Test: 0.4450\n",
      "Epoch: 007, Loss: 0.9516, Train: 0.6129, Val: 0.5500, Test: 0.4900\n",
      "Epoch: 008, Loss: 0.9565, Train: 0.5657, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 009, Loss: 0.9588, Train: 0.5371, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 010, Loss: 0.9633, Train: 0.5386, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 011, Loss: 0.9541, Train: 0.5729, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 012, Loss: 0.9365, Train: 0.6186, Val: 0.5000, Test: 0.4900\n",
      "Epoch: 013, Loss: 0.9379, Train: 0.6529, Val: 0.5200, Test: 0.4900\n",
      "Epoch: 014, Loss: 0.9306, Train: 0.6771, Val: 0.5300, Test: 0.4900\n",
      "Epoch: 015, Loss: 0.9127, Train: 0.6814, Val: 0.5000, Test: 0.4900\n",
      "Epoch: 016, Loss: 0.9076, Train: 0.6886, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 017, Loss: 0.9115, Train: 0.6900, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 018, Loss: 0.9009, Train: 0.6929, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 019, Loss: 0.9011, Train: 0.6929, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 020, Loss: 0.8874, Train: 0.6986, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 021, Loss: 0.8889, Train: 0.7071, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 022, Loss: 0.8818, Train: 0.7100, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 023, Loss: 0.8677, Train: 0.7143, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 024, Loss: 0.8649, Train: 0.7129, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 025, Loss: 0.8568, Train: 0.7129, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 026, Loss: 0.8531, Train: 0.7171, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 027, Loss: 0.8310, Train: 0.7214, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 028, Loss: 0.8318, Train: 0.7314, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 029, Loss: 0.8169, Train: 0.7314, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 030, Loss: 0.8084, Train: 0.7357, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 031, Loss: 0.8030, Train: 0.7414, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 032, Loss: 0.7836, Train: 0.7414, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 033, Loss: 0.7783, Train: 0.7443, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 034, Loss: 0.7494, Train: 0.7529, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 035, Loss: 0.7514, Train: 0.7600, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 036, Loss: 0.7306, Train: 0.7729, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 037, Loss: 0.7157, Train: 0.7771, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 038, Loss: 0.7010, Train: 0.7714, Val: 0.4100, Test: 0.4900\n",
      "Epoch: 039, Loss: 0.6909, Train: 0.7786, Val: 0.4100, Test: 0.4900\n",
      "Epoch: 040, Loss: 0.6744, Train: 0.7943, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 041, Loss: 0.6544, Train: 0.8014, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 042, Loss: 0.6538, Train: 0.8157, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 043, Loss: 0.6117, Train: 0.8243, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 044, Loss: 0.6262, Train: 0.8271, Val: 0.4100, Test: 0.4900\n",
      "Epoch: 045, Loss: 0.6098, Train: 0.8386, Val: 0.4100, Test: 0.4900\n",
      "Epoch: 046, Loss: 0.5795, Train: 0.8443, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 047, Loss: 0.5629, Train: 0.8571, Val: 0.4100, Test: 0.4900\n",
      "Epoch: 048, Loss: 0.5501, Train: 0.8614, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 049, Loss: 0.5268, Train: 0.8686, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 050, Loss: 0.5291, Train: 0.8743, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 051, Loss: 0.4913, Train: 0.8843, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 052, Loss: 0.4985, Train: 0.8914, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 053, Loss: 0.4697, Train: 0.9043, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 054, Loss: 0.4675, Train: 0.9157, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 055, Loss: 0.4371, Train: 0.9214, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 056, Loss: 0.4257, Train: 0.9243, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 057, Loss: 0.4137, Train: 0.9314, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 058, Loss: 0.3926, Train: 0.9414, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 059, Loss: 0.3951, Train: 0.9443, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 060, Loss: 0.3809, Train: 0.9457, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 061, Loss: 0.3431, Train: 0.9486, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 062, Loss: 0.3405, Train: 0.9543, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 063, Loss: 0.3265, Train: 0.9629, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 064, Loss: 0.3282, Train: 0.9643, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 065, Loss: 0.3278, Train: 0.9729, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 066, Loss: 0.3172, Train: 0.9743, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 067, Loss: 0.2880, Train: 0.9800, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 068, Loss: 0.2901, Train: 0.9829, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 069, Loss: 0.2685, Train: 0.9843, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 070, Loss: 0.2632, Train: 0.9857, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 071, Loss: 0.2590, Train: 0.9857, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 072, Loss: 0.2350, Train: 0.9886, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 073, Loss: 0.2295, Train: 0.9914, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 074, Loss: 0.2411, Train: 0.9914, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 075, Loss: 0.2303, Train: 0.9929, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 076, Loss: 0.2200, Train: 0.9957, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 077, Loss: 0.2048, Train: 0.9971, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 078, Loss: 0.2127, Train: 0.9957, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 079, Loss: 0.2082, Train: 0.9971, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 080, Loss: 0.1931, Train: 0.9986, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 081, Loss: 0.1908, Train: 0.9971, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 082, Loss: 0.1825, Train: 0.9986, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 083, Loss: 0.1887, Train: 0.9986, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 084, Loss: 0.1791, Train: 0.9986, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 085, Loss: 0.1742, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 086, Loss: 0.1695, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 087, Loss: 0.1566, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 088, Loss: 0.1797, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 089, Loss: 0.1651, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 090, Loss: 0.1417, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 091, Loss: 0.1452, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 092, Loss: 0.1562, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 093, Loss: 0.1439, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 094, Loss: 0.1476, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 095, Loss: 0.1508, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 096, Loss: 0.1189, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 097, Loss: 0.1309, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 098, Loss: 0.1315, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 099, Loss: 0.1183, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 100, Loss: 0.1321, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 101, Loss: 0.1227, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 102, Loss: 0.1189, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 103, Loss: 0.1185, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 104, Loss: 0.1206, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 105, Loss: 0.1199, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 106, Loss: 0.1178, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 107, Loss: 0.1275, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 108, Loss: 0.1281, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 109, Loss: 0.0974, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 110, Loss: 0.1109, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 111, Loss: 0.1167, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 112, Loss: 0.0922, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 113, Loss: 0.1198, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 114, Loss: 0.0985, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 115, Loss: 0.1023, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 116, Loss: 0.1129, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 117, Loss: 0.1166, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 118, Loss: 0.1082, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 119, Loss: 0.1088, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 120, Loss: 0.0995, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 121, Loss: 0.1125, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 122, Loss: 0.1016, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 123, Loss: 0.0969, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 124, Loss: 0.1118, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 125, Loss: 0.1168, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 126, Loss: 0.1066, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 127, Loss: 0.0946, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 128, Loss: 0.0837, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 129, Loss: 0.0849, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 130, Loss: 0.0958, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 131, Loss: 0.0951, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 132, Loss: 0.0772, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 133, Loss: 0.0898, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 134, Loss: 0.1055, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 135, Loss: 0.1044, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 136, Loss: 0.1068, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 137, Loss: 0.0911, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 138, Loss: 0.0847, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 139, Loss: 0.1051, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 140, Loss: 0.1156, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 141, Loss: 0.0786, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 142, Loss: 0.0897, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 143, Loss: 0.0917, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 144, Loss: 0.0852, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 145, Loss: 0.0852, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 146, Loss: 0.0848, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 147, Loss: 0.0822, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 148, Loss: 0.0714, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 149, Loss: 0.0824, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 150, Loss: 0.0767, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 151, Loss: 0.0831, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 152, Loss: 0.0891, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 153, Loss: 0.0828, Train: 1.0000, Val: 0.4100, Test: 0.4900\n",
      "Epoch: 154, Loss: 0.0762, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 155, Loss: 0.0805, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 156, Loss: 0.0835, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 157, Loss: 0.0940, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 158, Loss: 0.0890, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 159, Loss: 0.0997, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 160, Loss: 0.0841, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 161, Loss: 0.0945, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 162, Loss: 0.0774, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 163, Loss: 0.0737, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 164, Loss: 0.0747, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 165, Loss: 0.0929, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 166, Loss: 0.0955, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 167, Loss: 0.0992, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 168, Loss: 0.0780, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 169, Loss: 0.0923, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 170, Loss: 0.0786, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 171, Loss: 0.0911, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 172, Loss: 0.0860, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 173, Loss: 0.0696, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 174, Loss: 0.0914, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 175, Loss: 0.0811, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 176, Loss: 0.0700, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 177, Loss: 0.0814, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 178, Loss: 0.0838, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 179, Loss: 0.0732, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 180, Loss: 0.0743, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 181, Loss: 0.0966, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 182, Loss: 0.0687, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 183, Loss: 0.0800, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 184, Loss: 0.0762, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 185, Loss: 0.0921, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 186, Loss: 0.0729, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 187, Loss: 0.0701, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 188, Loss: 0.1010, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 189, Loss: 0.0678, Train: 1.0000, Val: 0.4100, Test: 0.4900\n",
      "Epoch: 190, Loss: 0.0659, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 191, Loss: 0.0805, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 192, Loss: 0.0701, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 193, Loss: 0.0746, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 194, Loss: 0.0712, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 195, Loss: 0.0688, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 196, Loss: 0.0653, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 197, Loss: 0.0702, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 198, Loss: 0.0807, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 199, Loss: 0.0771, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 200, Loss: 0.0738, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 201, Loss: 0.0825, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 202, Loss: 0.0737, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 203, Loss: 0.0775, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 204, Loss: 0.0665, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 205, Loss: 0.0595, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 206, Loss: 0.0910, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 207, Loss: 0.0842, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 208, Loss: 0.0666, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 209, Loss: 0.0785, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 210, Loss: 0.0670, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 211, Loss: 0.0684, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 212, Loss: 0.0671, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 213, Loss: 0.0639, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 214, Loss: 0.0666, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 215, Loss: 0.0722, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 216, Loss: 0.0722, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 217, Loss: 0.0655, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 218, Loss: 0.0842, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 219, Loss: 0.0637, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 220, Loss: 0.0743, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 221, Loss: 0.0667, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 222, Loss: 0.0586, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 223, Loss: 0.0714, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 224, Loss: 0.0611, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 225, Loss: 0.0587, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 226, Loss: 0.0636, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 227, Loss: 0.0806, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 228, Loss: 0.0616, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 229, Loss: 0.0675, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 230, Loss: 0.0658, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 231, Loss: 0.0640, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 232, Loss: 0.0636, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 233, Loss: 0.0767, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 234, Loss: 0.0774, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 235, Loss: 0.0766, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 236, Loss: 0.0607, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 237, Loss: 0.0755, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 238, Loss: 0.0719, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 239, Loss: 0.0603, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 240, Loss: 0.0695, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 241, Loss: 0.0706, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 242, Loss: 0.0799, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 243, Loss: 0.0742, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 244, Loss: 0.0629, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 245, Loss: 0.0637, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 246, Loss: 0.0648, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 247, Loss: 0.0681, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 248, Loss: 0.0662, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 249, Loss: 0.0660, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 250, Loss: 0.0792, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 251, Loss: 0.0615, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 252, Loss: 0.0639, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 253, Loss: 0.0693, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 254, Loss: 0.0571, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 255, Loss: 0.0579, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 256, Loss: 0.0886, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 257, Loss: 0.0535, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 258, Loss: 0.0650, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 259, Loss: 0.0671, Train: 1.0000, Val: 0.4100, Test: 0.4900\n",
      "Epoch: 260, Loss: 0.0589, Train: 1.0000, Val: 0.4000, Test: 0.4900\n",
      "Epoch: 261, Loss: 0.0786, Train: 1.0000, Val: 0.4100, Test: 0.4900\n",
      "Epoch: 262, Loss: 0.0637, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 263, Loss: 0.0614, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 264, Loss: 0.0626, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 265, Loss: 0.0654, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 266, Loss: 0.0717, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 267, Loss: 0.0602, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 268, Loss: 0.0679, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 269, Loss: 0.0785, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 270, Loss: 0.0576, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 271, Loss: 0.0594, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 272, Loss: 0.0682, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 273, Loss: 0.0719, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 274, Loss: 0.0553, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 275, Loss: 0.0564, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 276, Loss: 0.0494, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 277, Loss: 0.0716, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 278, Loss: 0.0507, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 279, Loss: 0.0598, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 280, Loss: 0.0749, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 281, Loss: 0.0622, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 282, Loss: 0.0691, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 283, Loss: 0.0777, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 284, Loss: 0.0689, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 285, Loss: 0.0584, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 286, Loss: 0.0620, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 287, Loss: 0.0783, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 288, Loss: 0.0617, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 289, Loss: 0.0631, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 290, Loss: 0.0523, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 291, Loss: 0.0709, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 292, Loss: 0.0745, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 293, Loss: 0.0623, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 294, Loss: 0.0589, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 295, Loss: 0.0592, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 296, Loss: 0.0625, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 297, Loss: 0.0597, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 298, Loss: 0.0525, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 299, Loss: 0.0695, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 300, Loss: 0.0563, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 301, Loss: 0.0566, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 302, Loss: 0.0741, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 303, Loss: 0.0600, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 304, Loss: 0.0728, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 305, Loss: 0.0576, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 306, Loss: 0.0602, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 307, Loss: 0.0535, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 308, Loss: 0.0529, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 309, Loss: 0.0559, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 310, Loss: 0.0579, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 311, Loss: 0.0572, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 312, Loss: 0.0483, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 313, Loss: 0.0605, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 314, Loss: 0.0552, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 315, Loss: 0.0670, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 316, Loss: 0.0618, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 317, Loss: 0.0463, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 318, Loss: 0.0660, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 319, Loss: 0.0716, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 320, Loss: 0.0608, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 321, Loss: 0.0711, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 322, Loss: 0.0563, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 323, Loss: 0.0715, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 324, Loss: 0.0685, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 325, Loss: 0.0599, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 326, Loss: 0.0808, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 327, Loss: 0.0755, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 328, Loss: 0.0522, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 329, Loss: 0.0655, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 330, Loss: 0.0690, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 331, Loss: 0.0560, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 332, Loss: 0.0684, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 333, Loss: 0.0621, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 334, Loss: 0.0610, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 335, Loss: 0.0848, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 336, Loss: 0.0568, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 337, Loss: 0.0683, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 338, Loss: 0.0614, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 339, Loss: 0.0509, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 340, Loss: 0.0652, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 341, Loss: 0.0658, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 342, Loss: 0.0580, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 343, Loss: 0.0607, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 344, Loss: 0.0733, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 345, Loss: 0.0688, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 346, Loss: 0.0669, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 347, Loss: 0.0633, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 348, Loss: 0.0664, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 349, Loss: 0.0690, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 350, Loss: 0.0666, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 351, Loss: 0.0533, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 352, Loss: 0.0570, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 353, Loss: 0.0685, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 354, Loss: 0.0656, Train: 1.0000, Val: 0.5100, Test: 0.4900\n",
      "Epoch: 355, Loss: 0.0588, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 356, Loss: 0.0608, Train: 1.0000, Val: 0.5000, Test: 0.4900\n",
      "Epoch: 357, Loss: 0.0507, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 358, Loss: 0.0471, Train: 1.0000, Val: 0.5100, Test: 0.4900\n",
      "Epoch: 359, Loss: 0.0581, Train: 1.0000, Val: 0.5000, Test: 0.4900\n",
      "Epoch: 360, Loss: 0.0672, Train: 1.0000, Val: 0.5000, Test: 0.4900\n",
      "Epoch: 361, Loss: 0.0596, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 362, Loss: 0.0753, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 363, Loss: 0.0549, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 364, Loss: 0.0545, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 365, Loss: 0.0572, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 366, Loss: 0.0640, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 367, Loss: 0.0524, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 368, Loss: 0.0605, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 369, Loss: 0.0683, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 370, Loss: 0.0623, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 371, Loss: 0.0634, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 372, Loss: 0.0598, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 373, Loss: 0.0590, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 374, Loss: 0.0602, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 375, Loss: 0.0540, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 376, Loss: 0.0637, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 377, Loss: 0.0566, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 378, Loss: 0.0634, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 379, Loss: 0.0616, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 380, Loss: 0.0702, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 381, Loss: 0.0537, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 382, Loss: 0.0598, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 383, Loss: 0.0692, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 384, Loss: 0.0616, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 385, Loss: 0.0566, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 386, Loss: 0.0536, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 387, Loss: 0.0514, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 388, Loss: 0.0594, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 389, Loss: 0.0604, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 390, Loss: 0.0592, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 391, Loss: 0.0503, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 392, Loss: 0.0625, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 393, Loss: 0.0551, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 394, Loss: 0.0590, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 395, Loss: 0.0647, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 396, Loss: 0.0714, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 397, Loss: 0.0585, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 398, Loss: 0.0664, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 399, Loss: 0.0607, Train: 1.0000, Val: 0.4100, Test: 0.4900\n",
      "Epoch: 400, Loss: 0.0739, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 401, Loss: 0.0616, Train: 1.0000, Val: 0.4100, Test: 0.4900\n",
      "Epoch: 402, Loss: 0.0575, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 403, Loss: 0.0672, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 404, Loss: 0.0529, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 405, Loss: 0.0581, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 406, Loss: 0.0582, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 407, Loss: 0.0644, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 408, Loss: 0.0561, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 409, Loss: 0.0464, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 410, Loss: 0.0477, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 411, Loss: 0.0491, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 412, Loss: 0.0518, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 413, Loss: 0.0606, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 414, Loss: 0.0563, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 415, Loss: 0.0539, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 416, Loss: 0.0571, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 417, Loss: 0.0462, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 418, Loss: 0.0526, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 419, Loss: 0.0568, Train: 1.0000, Val: 0.5000, Test: 0.4900\n",
      "Epoch: 420, Loss: 0.0568, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 421, Loss: 0.0524, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 422, Loss: 0.0561, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 423, Loss: 0.0766, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 424, Loss: 0.0640, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 425, Loss: 0.0640, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 426, Loss: 0.0430, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 427, Loss: 0.0493, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 428, Loss: 0.0642, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 429, Loss: 0.0483, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 430, Loss: 0.0584, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 431, Loss: 0.0644, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 432, Loss: 0.0525, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 433, Loss: 0.0555, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 434, Loss: 0.0602, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 435, Loss: 0.0639, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 436, Loss: 0.0467, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 437, Loss: 0.0471, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 438, Loss: 0.0510, Train: 1.0000, Val: 0.4100, Test: 0.4900\n",
      "Epoch: 439, Loss: 0.0582, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 440, Loss: 0.0526, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 441, Loss: 0.0576, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 442, Loss: 0.0542, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 443, Loss: 0.0451, Train: 1.0000, Val: 0.4100, Test: 0.4900\n",
      "Epoch: 444, Loss: 0.0687, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 445, Loss: 0.0485, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 446, Loss: 0.0528, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 447, Loss: 0.0563, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 448, Loss: 0.0531, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 449, Loss: 0.0605, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 450, Loss: 0.0711, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 451, Loss: 0.0430, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 452, Loss: 0.0521, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 453, Loss: 0.0663, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 454, Loss: 0.0544, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 455, Loss: 0.0487, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 456, Loss: 0.0595, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 457, Loss: 0.0430, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 458, Loss: 0.0606, Train: 1.0000, Val: 0.4800, Test: 0.4900\n",
      "Epoch: 459, Loss: 0.0567, Train: 1.0000, Val: 0.4900, Test: 0.4900\n",
      "Epoch: 460, Loss: 0.0557, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 461, Loss: 0.0593, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 462, Loss: 0.0465, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 463, Loss: 0.0671, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 464, Loss: 0.0548, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 465, Loss: 0.0542, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 466, Loss: 0.0631, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 467, Loss: 0.0625, Train: 1.0000, Val: 0.4700, Test: 0.4900\n",
      "Epoch: 468, Loss: 0.0525, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 469, Loss: 0.0615, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 470, Loss: 0.0568, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 471, Loss: 0.0512, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 472, Loss: 0.0472, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 473, Loss: 0.0543, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 474, Loss: 0.0448, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 475, Loss: 0.0620, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 476, Loss: 0.0506, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 477, Loss: 0.0591, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 478, Loss: 0.0602, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 479, Loss: 0.0506, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 480, Loss: 0.0644, Train: 1.0000, Val: 0.4500, Test: 0.4900\n",
      "Epoch: 481, Loss: 0.0545, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 482, Loss: 0.0521, Train: 1.0000, Val: 0.4600, Test: 0.4900\n",
      "Epoch: 483, Loss: 0.0488, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 484, Loss: 0.0495, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 485, Loss: 0.0568, Train: 1.0000, Val: 0.4400, Test: 0.4900\n",
      "Epoch: 486, Loss: 0.0659, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 487, Loss: 0.0504, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 488, Loss: 0.0488, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 489, Loss: 0.0486, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 490, Loss: 0.0466, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 491, Loss: 0.0449, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 492, Loss: 0.0560, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Epoch: 493, Loss: 0.0522, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 494, Loss: 0.0490, Train: 1.0000, Val: 0.4100, Test: 0.4900\n",
      "Epoch: 495, Loss: 0.0439, Train: 1.0000, Val: 0.4100, Test: 0.4900\n",
      "Epoch: 496, Loss: 0.0393, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 497, Loss: 0.0509, Train: 1.0000, Val: 0.4100, Test: 0.4900\n",
      "Epoch: 498, Loss: 0.0423, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 499, Loss: 0.0667, Train: 1.0000, Val: 0.4200, Test: 0.4900\n",
      "Epoch: 500, Loss: 0.0550, Train: 1.0000, Val: 0.4300, Test: 0.4900\n",
      "Median time per epoch: 0.0578s\n"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "best_val_acc = final_test_acc = 0\n",
    "for epoch in range(1, 501):\n",
    "    start = time.time()\n",
    "    loss = train()\n",
    "    train_acc, val_acc, tmp_test_acc = test()\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        test_acc = tmp_test_acc\n",
    "        torch.save(model.state_dict(), f'processed_data/model_weights_rgcn_{num_patients}.pth')\n",
    "    log(Epoch=epoch, Loss=loss, Train=train_acc, Val=val_acc, Test=test_acc)\n",
    "    times.append(time.time() - start)\n",
    "print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.5349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load(f'processed_data/model_weights_rgcn_{num_patients}.pth', weights_only=True))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(data.edge_index, data.edge_type).cpu()\n",
    "    prob = F.softmax(out, dim=1)\n",
    "auc = roc_auc_score(data.test_y.cpu(), prob[data.test_idx.cpu()], multi_class='ovr')\n",
    "print(f'ROC AUC score: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "pred = model(data.edge_index, data.edge_type).argmax(dim=-1)\n",
    "matrix = confusion_matrix(data.test_y.cpu(), pred[data.test_idx].cpu())\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=[\"Back2Home\", \"Reabilitation\", \"Death\"])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurovasc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
