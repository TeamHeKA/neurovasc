{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPHN KG Data Preprocessing for Node Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.predict import predict_target\n",
    "from pykeen.pipeline import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load KG and remove outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patients = 1000\n",
    "df = pd.read_csv(f\"../Data Generation/sphn_transductive_{num_patients}_0.nt\", sep=\" \", header=None)\n",
    "df.drop(columns=df.columns[-1], axis=1, inplace=True)\n",
    "df.columns=['s', 'r', 'd']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outcomes from KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = df['d'].str.contains('outcome_0.0|outcome_1.0|outcome_2.0')\n",
    "node_df = df[~outcome]\n",
    "node_df = node_df.reset_index(drop=True)\n",
    "outcome = node_df['s'].str.contains('outcome_0.0|outcome_1.0|outcome_2.0')\n",
    "node_df = node_df[~outcome]\n",
    "node_df = node_df.reset_index(drop=True)\n",
    "\n",
    "ent_to_id = {k: v for v, k in enumerate(set(node_df['s']).union(set(node_df['d'])), start=0)}\n",
    "rel_to_id = {k: v for v, k in enumerate(set(node_df['r']), start=0)}\n",
    "\n",
    "patients = [f\"<http://nvasc.org/synth_patient_{i}>\" for i in range(num_patients)]\n",
    "patient_id = []\n",
    "for patient in patients:\n",
    "    patient_id.append(ent_to_id[patient])\n",
    "\n",
    "num_nodes = max(ent_to_id.values()) + 1\n",
    "num_rels = max(rel_to_id.values()) + 1\n",
    "\n",
    "events = node_df.copy()\n",
    "events[\"s\"] = node_df.s.map(ent_to_id)\n",
    "events[\"d\"] = node_df.d.map(ent_to_id)\n",
    "events[\"r\"] = node_df.r.map(rel_to_id)\n",
    "\n",
    "ent_to_id = pd.DataFrame.from_dict(ent_to_id, orient='index')\n",
    "rel_to_id = pd.DataFrame.from_dict(rel_to_id, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save events, entities and relations to 'processed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'processed_data'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "events.to_csv(f'{path}/sphn_events_{num_patients}_noOutcome.tsv', sep='\\t', index=False, header=None)\n",
    "ent_to_id.to_csv(f'{path}/sphn_entities_{num_patients}_noOutcome.tsv', sep='\\t', header=None)\n",
    "rel_to_id.to_csv(f'{path}/sphn_relations_{num_patients}_noOutcome.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get numerical literals (including timestamps) and save to 'processed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_to_id = pd.read_csv(f'{path}/sphn_entities_{num_patients}_noOutcome.tsv', sep='\\t', header=None)\n",
    "entity = pd.DataFrame({'id': ent_to_id[1].values, 'ent': ent_to_id[0].values})\n",
    "\n",
    "# Get numeric values\n",
    "numeric = node_df[node_df['r'] == '<http://sphn.org/hasValue>']\n",
    "\n",
    "\n",
    "times = node_df[node_df['r'].str.contains('<http://sphn.org/hasStartDateTime>|<http://sphn.org/hasDeterminationDateTime>')]\n",
    "time = times.d.str.removesuffix('^^<http://www.w3.org/2001/XMLSchema#dateTime>')\n",
    "for i, t in time.items():\n",
    "    td = datetime.strptime(t, '%Y-%m-%dT%H:%M:%S') - datetime(2020,1,1)\n",
    "    times.d.loc[i] = td.total_seconds()\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n",
    "qt = QuantileTransformer(n_quantiles=10, random_state=0)\n",
    "scaled_ages = qt.fit_transform(numeric.d.values.reshape(-1,1))\n",
    "numeric['age'] = list(scaled_ages.reshape(-1,))\n",
    "\n",
    "numeric_embedding = np.zeros((len(entity), 1))\n",
    "for i, v in numeric.d.items():\n",
    "    idx = entity[entity.ent == v].id\n",
    "    numeric_embedding[idx] = numeric.age.loc[i]\n",
    "\n",
    "# pt = PowerTransformer()\n",
    "# scaled_times = pt.fit_transform(np.asarray(secs).reshape(-1,1))\n",
    "qt = QuantileTransformer(n_quantiles=10, random_state=0)\n",
    "scaled_times = qt.fit_transform(times.d.values.reshape(-1,1))\n",
    "times['sec'] = list(scaled_times.reshape(-1,))\n",
    "for i, v in times.d.items():\n",
    "    idx = entity[entity.ent == v].id\n",
    "    numeric_embedding[idx] = times.sec.loc[i]\n",
    "\n",
    "print(numeric_embedding)\n",
    "np.save(f\"processed_data/sphn_numeric_{num_patients}.npy\", numeric_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurovasc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
